{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e02aea",
   "metadata": {},
   "source": [
    "# AIO Q1 -- Data Analysis and Visualization\n",
    "In this test we will look at some real world data and do some data analysis and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b1693",
   "metadata": {},
   "source": [
    "## 0 -- imports\n",
    "Here are the libraries that you are allowed to use for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129403e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee4815",
   "metadata": {},
   "source": [
    "## 1 -- Dataloading (5)\n",
    "First we must load the data from the attached csv, 'data_by_zip.csv' which contains a complex US energy dataset. You should open the CSV to get a sense of the data, though it will be too large for you to fully read.  (This data is taken from this paper: https://dl.acm.org/doi/10.1145/3679240.3734603 -- you may look it over another time if you are curious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc2600",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Load the csv data into a pandas dataframe -- then print out the dimensions of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731a761",
   "metadata": {},
   "source": [
    "## 2 -- Data Cleaning (10)\n",
    "Now we will clean our data by removing NA values and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991fe79c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO First, replace all NA values (i.e. missing values) with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba9a47",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Then, for each column with numeral entries remove all rows whose value in that column is more than 3 stardard deviations from the mean of the column.\n",
    "# A row should be removed from the dataset if it is an outlier in *any* column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa582af1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO After this step you should save this dataframe as a csv named 'clean_data_by_zip.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a7f2fd",
   "metadata": {},
   "source": [
    "## 3 -- Simple Scatter Plot (10)\n",
    "We will do an initial visualization of some of the features of out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b2fff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Create a scatter plot where each row (i.e. Zipcode) is a point with the following axes:\n",
    "# X axis: The value corresponding to the 'yearly_sunlight_kwh_kw_threshold_avg' key -- this is the amount of energy (kWh) produced in an average year by a 1 kW solar panel in that Zipcode\n",
    "# Y axis: The value corresponding to the 'carbon_offset_metric_tons_per_panel' key -- this is the amount of CO2 that would not be emitted for every kWh of energy produced via clean energy.\n",
    "# Axes should be labelled appropriately and a title should be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88407c8f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Modify your plot such that the ZipCodes from California are all in a different color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a63be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Further modify your plot such that there is a vertical dotted line (gray with alpha = 0.5) showing the average yearly sunlight value\n",
    "# And a similar horizontal line for the y axis average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f8cc9",
   "metadata": {},
   "source": [
    "## 4 -- Generalized Scatter plot (10)\n",
    "Now we will write a function that can generalize this to arbitrary keys and subsets of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f27678",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Complete the following plotting function, instructions are given via the comment\n",
    "\n",
    "def scatter_plot(x_values, y_values, stats_line=None, masks=None):\n",
    "    '''\n",
    "    Params:\n",
    "    x_values: values to be plotted on the x axis\n",
    "    y_values: values to be plotted on the y axis\n",
    "    stats_line: Determines the type of stat line to add to the plot (None wil plot nothing, 'mean' will add mean lines as above, 'median' will add a line for the median on each axis)\n",
    "    masks: A list of tuples, with each tuple (i.e. each mask) having 3 elements:\n",
    "        1. A binary mask (i.e. np Array) of the same length as the data where 1 corresponds to the data point at that index being included and 0 to it being exluded\n",
    "        2. A name to add to the legend for this subset (e.g. 'CA Zipcodes')\n",
    "        3. A color for those datapoints to be set to.\n",
    "\n",
    "    '''\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284bcf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Show that your function works by reproducing your plot from above using a call to this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a0dec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO show that it works with other values by producing a new graph plotting 'Total_Population' versus 'existing_installs_count'\n",
    "# With lines showing the median drawn\n",
    "# And with CA zipcodes drawn in green and MA zipcodes drawn in black."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abe022",
   "metadata": {},
   "source": [
    "## 5 -- Complex Scatters/polynomial fits (30)\n",
    "Now we will modify our code to include polynomial fits to our masked subsets. Doing only a linear fit will give 50% credit on this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f0482",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO modify your above code such that a new element is added to your 'masks' tuples as explained below\n",
    "\n",
    "def complex_scatter_plot(x_values, y_values, stats_line=None, masks=None):\n",
    "    '''\n",
    "    Modification: Add a 4th element to each mask tuple which is an integer representing the degree of fit to be shown. \n",
    "    E.G. if a tuple is : ([0,1,0,1, ...], 'Even data', 'blue', 5) then there should be a 5 degree polynomial fit of the data corresponding to the mask\n",
    "    added to the plot, it should be the same color as the data itself but with alpha=0.5.\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e377f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO show that your code works by showing the plots from part 4 with each mask having a 4 degree polynomial fit. Show only linear fits if that is the only fit completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7125812",
   "metadata": {},
   "source": [
    "## 6 -- Pearson Correlation (10)\n",
    "We will now implement a pearson correlation calculation for any two sets of values. The Pearson correlation coefficient intuitively represents how closesly two sets, X and Y, are to a purely linear relationship (i.e. Y = w * X + b, for some w and b) with value 1 meaning a perfect linear fit and 0 meaning completely uncorrelated data.\n",
    "<\\br><\\br>\n",
    "Specifically Pearson Correlation Coefficient (PCC) is calculated like so:\n",
    "\\begin{align*}\n",
    "PCC(X,Y) = \\frac{cov(X,Y)}{\\sigma_X \\sigma_Y}\n",
    "\\end{align*}\n",
    "Where, \n",
    "\\begin{align*}\n",
    "cov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)]\n",
    "\\end{align*}\n",
    "With: $\\mu_X$ is the average of X and $\\sigma_X$ is the standard deviation of X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4739f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO complete the implementation of Pearson Correlation\n",
    "\n",
    "def pearson_corr(X, Y):\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5dcb7b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO report the pearson correlation of the following pairs:\n",
    "\n",
    "'''\n",
    "total population vs existing installs:\n",
    "    - In all ZIP codes\n",
    "    - In CA ZIP codes\n",
    "    - In MA ZIP codes\n",
    "\n",
    "Median Income (find the exact key in the csv) vs installs per capita (existing installs / population of each ZIP)\n",
    "    - In all ZIP codes\n",
    "    - In CA ZIP codes\n",
    "    - In MA ZIP codes    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45484f",
   "metadata": {},
   "source": [
    "## 7 -- Pearson correlation heatmap (15)\n",
    "Now we will use our pearson correlation calculations to produce heatmaps for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce790b70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO complete the heatmap function below\n",
    "\n",
    "def pearson_heatmap(dataframe, keys):\n",
    "    '''\n",
    "    dataframe: a Pandas Dataframe of zip codes -- this will either be the entire dataset from the csv, or some subset.\n",
    "    keys: a list of keys (i.e. col of the dataframe) which we will find the p-corr between.\n",
    "\n",
    "    This should plot a heatmap (via seaborn) the pearson correlation between each pair of keys. \n",
    "    For the scale of the heatmap color you should show all p-corr(x,x) (i.e. the p-corr between a col and itself) to be the average of all other (non symmetric) correlations\n",
    "    '''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b4633",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO use this to show the pearson correlations of the following keys\n",
    "\n",
    "keys = ['Median_income', 'existing_installs_count', 'black_prop', 'asian_prop', 'yearly_sunlight_kwh_kw_threshold_avg', 'carbon_offset_metric_tons', 'Total_Population']\n",
    "\n",
    "# For: all the zips, just CA zips, just MA zips, and just MI zips -- that is 4 heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c1fd6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Additionally, for each state-specific heatmap show the different of the heatmap to the all ZIP heatmap (that is, a new heatmap with the diagnoal entries = 0) \n",
    "# And report the correlation entry which is most different for each of these states compared to the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5f6da",
   "metadata": {},
   "source": [
    "## 8 -- Conclusion Analysis (10)\n",
    "Now, using all of the results that you've visualized, make some conclusions -- you are graded here based on the correctness of your conclusion and how compelling the argument you make is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58867fc2",
   "metadata": {},
   "source": [
    "#### 8a. If the intention of installing solar panels is to both increase energy generation and carbon offset how good is the current distribution of panels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a606a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8267a4ec",
   "metadata": {},
   "source": [
    "#### 8b. If you were to add n new solar panels in zip codes of your choosing how would you decide where to put them if attempting to co-maximize energy generation and carbon offset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b79f71a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f93ddda5",
   "metadata": {},
   "source": [
    "## END OF MOCK AIO QUESTION --------------------------------------------------------\n",
    "Below are some extention questions for interested students. In particular, this is the begininng of my recent research work (1st paper is: https://dl.acm.org/doi/10.1145/3679240.3734603, 2nd is here: https://dl.acm.org/doi/pdf/10.1145/3736425.3770115, 3rd is being published soon but I can share it if you are interested). If any of you are interested and able to work on this effectively then I would consider a research mentorship to help on the 4th/5th paper in the series and perhaps earn authorship.\n",
    "</br></br>\n",
    "You may reference the library I created for these works (you can also find implementations of the problem you just did in it) here: https://github.com/coopersigrist/SunSight\n",
    "</br></br>\n",
    "If you finish all of these problems with high competency I will almost definitely take you on for the next paper and give you an authorship position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493fa5b",
   "metadata": {},
   "source": [
    "### EX 1. Find 3 other notable and relevant statistics from this data -- You may use any techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22573b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "189ec844",
   "metadata": {},
   "source": [
    "### EX 2. Create an algorithm which places n panels in zip codes with the goal to maximize energy generation and carbon offset. Give pseudo-code for your algorithm and show a map of the locations that 2 million panels would be placed (I recommend using the visualization in the SunSight library) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a738fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d88a308",
   "metadata": {},
   "source": [
    "### EX 3. Use the Sunsight library to create a projection of the success of your model in Carbon Offset and Energy Generation (like fig 6 + 7 in paper 1) compared to the baselines of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe63d6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7098061",
   "metadata": {},
   "source": [
    "### EX 4. Using the SunSight library replicate the results from the second paper (EVA implementation), namely fig 3 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b004b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4ae099b",
   "metadata": {},
   "source": [
    "### (*) EX 5. Modify the EVA method from paper 2 such that instead of placing panels in the highest value ZIPs it instead stochastically places them based on the Soft Max of the scores for all ZIP codes. Report the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7178e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "652a7541",
   "metadata": {},
   "source": [
    "### (**) EX 6. Modify the implementation of EVA further such that each objective is decomposed to be 50 objectives (1 for each state) -- that is, instead of having a national energy generation score, there should be 1 per state and the lexicase selection should choose some subsection of all of these objectives to use to select the surviving models in each iteration of NEAT. (If you end up working on this one I can meet with you briefly to explain if this is unclear)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3d11d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
