{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa003b20",
   "metadata": {},
   "source": [
    "# Derviving (a piece of) the Universal Approximator Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7bca4",
   "metadata": {},
   "source": [
    "For this problem we will work with functions with binary input and output, particualrly logical gates. The domain for each of these will be $[0,1]^n$ and the range will be $[0,1]$. That is each feature of the input is either 0 or 1 and so is the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796936cc",
   "metadata": {},
   "source": [
    "#### Q1. We will first define the AND(a,b) (also denoted $a \\land b$) and OR(a,b) (also denoted $a \\lor b$) functions. They are defined as follows:\n",
    "$$\n",
    "AND(a,b) = \n",
    "\\begin{cases}\n",
    "1 \\quad \\quad if \\quad a + b > 1 \\\\\n",
    "0 \\quad \\quad otherwise\n",
    "\\end{cases}\n",
    "$$\n",
    "$$\n",
    "OR(a,b) = \n",
    "\\begin{cases}\n",
    "1 \\quad \\quad if \\quad a + b > 0 \\\\\n",
    "0 \\quad \\quad otherwise\n",
    "\\end{cases}\n",
    "$$\n",
    "For each of these functions create determine the weights and bias of the following model such that it would perfectly behave as the function. (Note: > will output 1 if true or 0 if false)\n",
    "$$\n",
    "\\hat{y} = ([a,b] \\cdot W + b) > 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5860df",
   "metadata": {},
   "source": [
    "AND:\n",
    "</br></br>\n",
    "W = \n",
    "</br>\n",
    "b = \n",
    "</br></br>\n",
    "OR:\n",
    "</br></br>\n",
    "W = \n",
    "</br>\n",
    "b = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757b68b",
   "metadata": {},
   "source": [
    "#### Q2. Now we will extend this to the high-dimensional case -- we define X $\\in [0,1]^n$ with X = [$x_0, x_1, ..., x_n$]. AND(X) will be 1 if and only if *all* of X is 1. Likewise OR(X) will be 1 if and only if *any* element of X is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ce85e",
   "metadata": {},
   "source": [
    "Extend your previous result to produce weights and biases that will allow our model to exactly capture this behavior.\n",
    "</br></br>\n",
    "AND:\n",
    "</br></br>\n",
    "W = \n",
    "</br>\n",
    "b = \n",
    "</br></br>\n",
    "OR:\n",
    "</br></br>\n",
    "W = \n",
    "</br>\n",
    "b = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6160a7",
   "metadata": {},
   "source": [
    "#### Q3. We will also consider the negation of each of these, Not AND (NAND) and Not OR (NOR) respectively. These will produce exactly opposite outputs of their non-negated counterparts. Determine weights and biases for these. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fead25a",
   "metadata": {},
   "source": [
    "(Hint: neg f(a,b) = -1 * f(a,b) + 1) \n",
    "</br></br>\n",
    "NAND:\n",
    "</br></br>\n",
    "W = \n",
    "</br>\n",
    "b = \n",
    "</br></br>\n",
    "NOR:\n",
    "</br></br>\n",
    "W = \n",
    "</br>\n",
    "b = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391c4e8",
   "metadata": {},
   "source": [
    "#### Q4. Now consider the Exclusive OR (denoted XOR, or $\\oplus$). Which behaves like so:\n",
    "$$\n",
    "XOR(a,b) = \n",
    "\\begin{cases}\n",
    "1 \\quad \\quad if \\quad a + b == 1 \\\\\n",
    "0 \\quad \\quad otherwise\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99db7ad",
   "metadata": {},
   "source": [
    "Prove that this function *cannot* exactly be represented by the above model ($\\hat{y}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99f14d",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812be34",
   "metadata": {},
   "source": [
    "#### Q5. Show how the XOR function is representable by a two-layer version of the above model, particularly with:\n",
    "$$\\hat{y} = (((X \\cdot W_0 + b_0) > 0) \\cdot W_1 + b_1) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4efec5",
   "metadata": {},
   "source": [
    "(hint: $W_0$ may be a matrix and > acts as an element-wise function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ab966",
   "metadata": {},
   "source": [
    "$W_0$ = \n",
    "</br></br>\n",
    "$b_0$ = \n",
    "</br></br>\n",
    "$W_1$ = \n",
    "</br></br>\n",
    "$b_1$ = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986f657",
   "metadata": {},
   "source": [
    "#### Q6. Show how the XOR function can be considered a two-layer composition of the other logical functions descxribed in Q1-Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea9f3de",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce14665f",
   "metadata": {},
   "source": [
    "#### Q7.  Conjunctive normal form (CNF) is a possible form for any logical function, f. Particularly, it must be represented as a Conjunction (AND-ing) of OR functions. e.g.\n",
    "$$f(X) = AND(OR(x_0, x_1, x_5), OR(x_1, x_2, ... \\neg x_n), ...)$$\n",
    "Here, negation of the elements of the input is allowed. \n",
    "</br></br>\n",
    "Describe how to construct a two-layer model like above which can represent any function in CNF. This will prove that any logical function can be represented by a two-layer network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c8cc62",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c7c62",
   "metadata": {},
   "source": [
    "#### Q8. We will now introduce a new function, EQ(X,TARGET), which will output 1 if and only if all of the elements of X are equal to their conterparts in TARGET. Give the weights and bias of a *one-layer* network to represent this. (X and TARGET are still binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25541e7f",
   "metadata": {},
   "source": [
    "W = \n",
    "</br></br>\n",
    "b = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f6ca6",
   "metadata": {},
   "source": [
    "#### Q9. Using your representation of EQ, show how to construct a two-layer version of the IN(X, SET) function which will return 1 if the array X appears in the set of arrays SET. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b53421",
   "metadata": {},
   "source": [
    "(you may describe the construction procedure instead of giving the matrices if you are unable to format them nicely)\n",
    "\n",
    "$W_0$ = \n",
    "</br></br>\n",
    "$b_0$ = \n",
    "</br></br>\n",
    "$W_1$ = \n",
    "</br></br>\n",
    "$b_1$ = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce07c13",
   "metadata": {},
   "source": [
    "#### Q10. Show, using any of your previous results, that any function Integers to Integers with finite domain may be exactly represented using a two-layer model as above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9db28",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e387d3",
   "metadata": {},
   "source": [
    "#### Q11. Extend this result to any finite-precision input (e.g. Floats). (This is still finitely many inputs/outputs though)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af823c90",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0c546",
   "metadata": {},
   "source": [
    "#### Q12. Consider now a function with finitely many, infinite-precision inputs (e.g. reals). Show that the Mean Squared Error (MSE) of a two-layer model's approximation of this function can be strictly reduced by increasing the number of weights and biases. This gives universal approximation of finite-domain infinite-precision functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ad219",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
