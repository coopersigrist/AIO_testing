{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852cc4a9",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors (KNN) and the curse of dimensionality.\n",
    "In this test we will implement and explore a one-shot method for learned classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13222f59",
   "metadata": {},
   "source": [
    "## Section 1 : Dataset (10 points)\n",
    "We will first set up a couple datasets to use as well as create visualizations for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_one = {'mean':(2,0.5), 'std':(2,1), 'n_points':100}\n",
    "class_two = {'mean':(0.5,1), 'std':(0.5,0.3), 'n_points':100}\n",
    "distributions = [class_one, class_two]\n",
    "\n",
    "def create_classification_data(distributions):\n",
    "    '''\n",
    "    Samples from the given gaussian distributions (each with mean, std, and number of points)\n",
    "    returns a single dataset of all points with class labels corresponding to the index of the distribution in the distributions list\n",
    "    \n",
    "    You may assume that each distribution has the same dimenstions. \n",
    "    '''\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa559b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the points given the example distributions, each class should be its own color.\n",
    "data = create_classification_data(distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4429225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Plot the points for data with these 3d distributions\n",
    "class_one = {'mean':(2,0.5,3), 'std':(2,1,1), 'n_points':20}\n",
    "class_two = {'mean':(0.5,1,0), 'std':(0.5,0.3,0), 'n_points':10}\n",
    "class_three = {'mean':(1,3,1), 'std':(2,0.5,2), 'n_points':30}\n",
    "distributions = [class_one, class_two, class_three]\n",
    "\n",
    "data = create_classification_data(distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc117f",
   "metadata": {},
   "source": [
    "## Section 2: K Nearest Neighbors (20 points)\n",
    "We will now implement a k-nearest neighbors classifier and observe its behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ad66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 points -- implementation\n",
    "\n",
    "def K_nearest_neighbor(k, point, data):\n",
    "    '''\n",
    "    Given a point (in cartesean space) determine the k closest (euclidean distance) datapoints. \n",
    "    Return an integer (0, ..., C) corresponding to the most common class out of those k points where C is the final class (number of classes -1)\n",
    "\n",
    "    Hint: Later sections may require you to run this on many datapoints, it may be beneficial to optimize the runtime of your algorithm\n",
    "    '''\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24dfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'mean': (2, 0.5, 3), 'std': (2, 1, 1), 'n_points': 10}, {'mean': (0.5, 1, 0), 'std': (0.5, 0.3, 0), 'n_points': 10}, {'mean': (1, 3, 1), 'std': (2, 0.5, 2), 'n_points': 10}]\n"
     ]
    }
   ],
   "source": [
    "# 5 points -- testing\n",
    "\n",
    "# TODO first measure the accuracy of your K nearest Neighbors implementation (5)\n",
    "def measure_accuracy(k, train_data, test_data):\n",
    "    '''\n",
    "    Train_data and Test_data will both be tuples of coordinates and a class label (integer 0,...,C)\n",
    "\n",
    "    Using your implementation of KNN and the training data predict a label for each test data point.\n",
    "    return the accuracy of these labels as a percentage.\n",
    "    '''\n",
    "\n",
    "    return\n",
    "\n",
    "train_data = create_classification_data(distributions)\n",
    "\n",
    "test_dist = [{a: (dist[a] if a != 'n_points' else 10) for a in dist} for dist in distributions] # dictionary + list comprehension to change n_points to 10 for all dists\n",
    "test_data = create_classification_data(test_dist)\n",
    "\n",
    "print(\"accuracy at k = 4:\", measure_accuracy(4,train_data,test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ffee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 points -- Plotting\n",
    "\n",
    "# TODO Plot k values versus accuracy, find the k value which has maximum accuracy.\n",
    "# Also plot the runtime versus k value using the time library\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c9eba",
   "metadata": {},
   "source": [
    "## Section 2.5 (Bonus) : Advanced Plotting (10 points)\n",
    "Here is a chance to show off your plotting and DP skills. Don't attempt this unless you are sure of both of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bfd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Create a plot of the decision boundaries of your KNN Clustering algorithm\n",
    "\n",
    "def plot_decision_boundary(k, train_data):\n",
    "    '''\n",
    "    This plot should have the training data plotted along with shaded regions for each of the areas in which your KNN classifies differently\n",
    "    Regions' colors should correspond to the classes they predict. \n",
    "    '''\n",
    "    pass\n",
    "\n",
    "# TODO Plot this for k = 1, k = 5 and your optimal k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36539332",
   "metadata": {},
   "source": [
    "## Section 3 : High Dimensionality (20 points)\n",
    "We will now explore how our method performs on high-dimensional data with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0368e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 points -- High Dimenstion Data Test\n",
    "\n",
    "# TODO modify your training and testing data to have 'additional_dims' additional dimensions all with mean 0 and std 0.2\n",
    "def create_noisy_high_dim_data(distbutions, additional_dims, mean=0, std=0.2):\n",
    "    '''\n",
    "    ex. for additional dims = 2:\n",
    "    {'mean':(2,0.5,3), 'std':(2,1,1), 'n_points':20} -> {'mean':(2,0.5,3,0,0), 'std':(2,1,1,0.2,0.2), 'n_points':20}\n",
    "\n",
    "    then sample using your previous method\n",
    "    '''\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 points -- plots (and runtime check)\n",
    "\n",
    "# TODO using your optimal k value from above, create plots showing the accuracy and runtime of your KNN given different values of 'additonal dims' up to 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b7fb66",
   "metadata": {},
   "source": [
    "### Question 3.1 (5 points)\n",
    "Explain why the above behavior is happening, should we expect the same on real-world data?\n",
    "</br></br>\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf2131",
   "metadata": {},
   "source": [
    "### Question 3.2 (5 points)\n",
    "Provide a method to mitigate this issue, be detailed in explaining the method and why it will help fix this problem.\n",
    "</br></br>\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046e5a7",
   "metadata": {},
   "source": [
    "## Section 3.5 (bonus) : 10 points\n",
    "Here you can implement your suggestion from 3.2, you will score points based off of the effect it has along with the generality of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement your fix here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af2ae67",
   "metadata": {},
   "source": [
    "## Section 4: Adverserial Data (20 points)\n",
    "Now we will look at an adverserial case and see if we have any way to still use KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 points -- Adverserial dataset\n",
    "\n",
    "def create_adverserial_data(max_n):\n",
    "    '''\n",
    "    This dataset will contain all points [0,max_n]^2 -- i.e. (0,0), (0,1), ... (0, max_n), ..., (max_n, max_n)\n",
    "    each point will be either class 0 or 1 which will be equal to its coordinates mod 2 (even or odd)\n",
    "\n",
    "    i.e.  (0,0) -> 0, (1,2) -> 1, ... (a, b) -> a+b % 2\n",
    "    '''\n",
    "\n",
    "    return\n",
    "\n",
    "adverserial_data = create_adverserial_data(10) # 121 points\n",
    "\n",
    "# TODO plot this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 points -- Testing on Adverserial Data\n",
    "\n",
    "# TODO create a plot of k versus accuracy (same as Section 2) for this new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b876557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 points -- Trigonometric Basis Expansion\n",
    "\n",
    "# TODO Write a method that will convert a dataset via trigonometric basis expansion.\n",
    "def trig_basis_expansion(data, scale):\n",
    "    '''\n",
    "    Basis expand the input data, such that:\n",
    "    (x,y) -> (sin(nx), cos(nx), sin(ny), cos(ny))\n",
    "\n",
    "    where n = scale\n",
    "    '''\n",
    "\n",
    "    return\n",
    "\n",
    "# TODO Seperate out 1/5 of the data points to create a train and test set, then (after basis expanding):\n",
    "# Plot your KNNs accuracy versus a few scale value in the range 1 - 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1055ab5",
   "metadata": {},
   "source": [
    "### Question 4.1 (5 points):\n",
    "What value(s) of scale allow for 100% accuracy on this particular dataset, why? Justify your answer.\n",
    "</br></br>\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e53ca3",
   "metadata": {},
   "source": [
    "## Section 5: Open Ended (30 points)\n",
    "Now we will try our method on a real Dataset to see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may use any libraries you would like for this section, though you MUST use your above implementation of KNN as the basis of your solution.\n",
    "\n",
    "# We will be using MNIST as the dataset (to make it tractable computationally)\n",
    "def load_mnist(batch_size=32, train=True):\n",
    "\n",
    "    to_tensor_transform = torchvision.transforms.ToTensor() # You may remove this if you would like to use non-tensors\n",
    "    dataset = torchvision.datasets.MNIST('../dataset/', train=train, download=True, transform=to_tensor_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) # You may also find it easier to deal with just the dataset and not the dataloader\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "train_dataset, train_dataloader = load_mnist()\n",
    "test_dataset, test_dataloader = load_mnist(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 points -- Test without modification\n",
    "\n",
    "# TODO test your model without modification (you may need to just use a subset of the dataset) and\n",
    "# plot k versus accuray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d804652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 points -- Any method you'd like\n",
    "\n",
    "# TODO Using any modifications of your choosing, implement a KNN which can accurately predict MNIST. \n",
    "# You must show plots which explain your models behavior and you should explain your methodology in a markdown section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
