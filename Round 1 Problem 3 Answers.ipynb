{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2025 USA-NA-AIO Round 1, Problem 3 â€” ANSWERS\n",
        "\n",
        "## Problem 3 (100 points)\n",
        "\n",
        "Before starting this problem, make sure to run the following code first without any change:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(2025)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## $\\color{red}{\\text{WARNING !!!}}$\n",
        "\n",
        "Beyond importing libraries/modules/classes/functions in the preceding cell, you are **NOT** allowed to import anything else for the following purposes:\n",
        "\n",
        "- As a part of your final solution. For instance, if a problem asks you to build a model without using sklearn but you use it, then you will not earn points.\n",
        "\n",
        "- Temporarily import something to assist you to get a solution. For instance, if a problem asks you to manually compute eigenvalues but you temporarily use `np.linalg.eig` to get an answer and then delete your code, then you violate the rule.\n",
        "\n",
        "**Rule of thumb:** Each part has its particular purpose to intentionally test you something. Do not attempt to find a shortcut to circumvent the rule.\n",
        "\n",
        "All coding tasks shall run on **CPUs, not GPUs**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 1 (5 points, coding task)\n",
        "\n",
        "We study the dataset `USAAIO_2025_round1_prob3_train.csv` provided in this contest.\n",
        "\n",
        "The dataset can be found here:\n",
        "\n",
        "`url = \"https://drive.google.com/file/d/125YsFPS2nCNRvYyy1tgnD8RhYIUglLX9/view?usp=sharing\"`\n",
        "\n",
        "Do the following tasks in this part.\n",
        "\n",
        "1. Load `USAAIO_2025_round1_prob3_train.csv` into a pandas DataFrame object called `df_1`.\n",
        "2. Print the first 10 rows.\n",
        "3. Define a function called `data_summary` that\n",
        "    - Takes a DataFrame object as an input.\n",
        "    - Prints the shape of the DataFrame.\n",
        "    - Prints the data type for each column.\n",
        "    - Prints the count of missing values for each column.\n",
        "    - Delivers no output.\n",
        "4. After defining the above function, call it by feeding `df_1` to it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "df_1 = pd.read_csv('USAAIO_2025_round1_prob3_train.csv')\n",
        "print(df_1.head(10))\n",
        "\n",
        "def data_summary(df):\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Data Types: {df.dtypes}\")\n",
        "    print(f\"Missing Values per Column: {df.isnull().sum()}\")\n",
        "\n",
        "data_summary(df_1)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2 (5 points, coding task)\n",
        "\n",
        "Do the following tasks in this part.\n",
        "\n",
        "1. Create a DataFrame object called `df_2` that keeps the following columns in `df_1` (all other columns in `df_1` shall not appear in `df_2`):\n",
        "    - `Survived`\n",
        "    - `Sex`\n",
        "    - `Age`\n",
        "    - `SibSp`\n",
        "    - `Parch`\n",
        "    - `Fare`\n",
        "    - `Embarked`\n",
        "2. Print the first 5 rows of `df_2`.\n",
        "3. Print the shape of `df_2`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "df_2 = df_1[['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "\n",
        "print(df_2.head())\n",
        "print(df_2.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 3 (5 points, coding task)\n",
        "\n",
        "Do the following tasks in this part.\n",
        "\n",
        "1. In `df_2`, remove all rows that contain null (missing) values.\n",
        "2. Save the updated DataFrame object as `df_3` (that is, the change of `df_2` should not be inplace).\n",
        "3. For `df_3`, print the count of missing values per column.\n",
        "4. Print the shape of `df_3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "df_3 = df_2.dropna()\n",
        "\n",
        "print(df_3.isnull().sum())\n",
        "\n",
        "print(df_3.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 4 (5 points, coding task)\n",
        "\n",
        "Do the following tasks in this part.\n",
        "\n",
        "1. Create a deep copy of `df_3`, named `df_4`.\n",
        "2. In `df_4`, create a new column called `GroupSize`. Its value is equal to `SibSp + Parch + 1`.\n",
        "3. Print the first five rows of `df_3` and `df_4`.\n",
        "4. Print the shapes of `df_3` and `df_4`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "df_4 = copy.deepcopy(df_3)\n",
        "\n",
        "df_4['GroupSize'] = df_4['SibSp'] + df_4['Parch'] + 1\n",
        "\n",
        "print(df_3.head())\n",
        "print(df_4.head())\n",
        "\n",
        "print(df_3.shape)\n",
        "print(df_4.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5 (5 points, coding task)\n",
        "\n",
        "Do the following tasks in this part.\n",
        "\n",
        "1. Remove columns `SibSp` and `Parch` in `df_4`, and save this new DataFrame object as `df_5` (changes on `df_4` should not be inplace).\n",
        "2. Print the first five rows of `df_4` and `df_5`.\n",
        "3. Print the shapes of `df_4` and `df_5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "df_5 = df_4.drop(columns=['SibSp', 'Parch'])\n",
        "\n",
        "print(df_4.head())\n",
        "print(df_5.head())\n",
        "\n",
        "print(df_4.shape)\n",
        "print(df_5.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 6 (5 points, coding and conceptual reasoning task)\n",
        "\n",
        "In `df_5`, columns `Sex` and `Embarked` are categorical data.\n",
        "\n",
        "Do the following tasks to process these categorical data.\n",
        "\n",
        "1. To do logistic regression on this dataset, we need to do one hot encoding on these two columns. Explain why?\n",
        "2. Do one hot encoding on these two columns. Set `drop_first = True` and `dtype = np.int8`. Save the new dataframe object as `df_6`.\n",
        "3. Explain what `drop_first = True` means and why we do so.\n",
        "4. Print the first five rows of `df_5` and `df_6`.\n",
        "5. Print the shapes of `df_5` and `df_6`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "# Question 1\n",
        "\"\"\"\n",
        "Answer:\n",
        "\n",
        "Logistic regression requires numerical data, not categorical data.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Question 2\n",
        "# Answer: (put your code here)\n",
        "\n",
        "df_6 = pd.get_dummies(df_5, columns=['Sex', 'Embarked'], drop_first = True, dtype = np.int8)\n",
        "\n",
        "# Question 3\n",
        "\"\"\"\n",
        "Answer:\n",
        "\n",
        "Suppose a categorical variable takes value k chosen from K categories, indexed as 0, 1, ..., K-1.\n",
        "\n",
        "By setting drop_first = True, it is replaced by a vector with shape K-1.\n",
        "\n",
        "If k = 0, then in this vector, all entries are 0.\n",
        "\n",
        "If k is not 0, then in this vector, the (k-1)th entry (entry indices starts from 0 and ends with K-2) is 1 and all other entries are 0.\n",
        "\n",
        "Setting drop_first = True avoids multicollinearity.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Question 4\n",
        "# Answer: (put your code here)\n",
        "\n",
        "print(df_5.head())\n",
        "print(df_6.head())\n",
        "\n",
        "# Question 5\n",
        "# Answer: (put your code here)\n",
        "\n",
        "print(df_5.shape)\n",
        "print(df_6.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 7 (5 points, coding task)\n",
        "\n",
        "Do the following tasks in this part.\n",
        "\n",
        "1. Define `X` that keeps all features in `df_6` and drops the label column `Survived`.\n",
        "2. Define `y` that keeps the label column `Survived` in `df_6` only.\n",
        "3. Print the types of objects `X` and `y`.\n",
        "4. Print the first five rows of `X` and the first five elements in `y`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "X = df_6.drop(columns=['Survived'])\n",
        "y = df_6['Survived']\n",
        "\n",
        "print(type(X))\n",
        "print(type(y))\n",
        "\n",
        "print(X.head())\n",
        "print(y.head())\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 8 (5 points, coding task)\n",
        "\n",
        "Do the following tasks in this part.\n",
        "\n",
        "1. Define a function called `my_train_test_split` that splits the whole dataset into the training component and the test/validation component.\n",
        "   - The split is random.\n",
        "   - **Inputs:**\n",
        "     - `X`: A DataFrame object of features of all sample data.\n",
        "     - `y`: A Series object of labels of all sample data.\n",
        "     - `test_size`: It takes a value between 0 and 1 that denotes the fraction of samples used for testing. That is, the number of samples used for testing is `int(total number of samples * test_size)`.\n",
        "   - **Outputs:**\n",
        "     - `X_train`: It keeps samples in `X` for training.\n",
        "     - `X_test`: It keeps samples in `X` for testing.\n",
        "     - `y_train`: It keeps samples in `y` for training.\n",
        "     - `y_test`: It keeps samples in `y` for testing.\n",
        "2. Call this function with inputs:\n",
        "   - `X = X`\n",
        "   - `y = y`\n",
        "   - `test_size = 0.2`\n",
        "3. Print object types and shapes of `X_train`, `X_test`, `y_train`, `y_test`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "def my_train_test_split(X, y, test_size):\n",
        "    num_samples = X.shape[0]\n",
        "    num_test_samples = int(num_samples * test_size)\n",
        "    indices = np.random.permutation(num_samples)\n",
        "    test_indices = indices[:num_test_samples]\n",
        "    train_indices = indices[num_test_samples:]\n",
        "\n",
        "    X_train = X.iloc[train_indices]\n",
        "    X_test = X.iloc[test_indices]\n",
        "    y_train = y.iloc[train_indices]\n",
        "    y_test = y.iloc[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = my_train_test_split(X, y, 0.2)\n",
        "\n",
        "print(type(X_train))\n",
        "print(type(X_test))\n",
        "print(type(y_train))\n",
        "print(type(y_test))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 9 (5 points, coding task)\n",
        "\n",
        "Use `StandardScaler` that has been imported from `sklearn.preprocessing` (**DO NOT IMPORT IT AGAIN**) to do the following tasks.\n",
        "\n",
        "1. Create an object called `scaler`.\n",
        "2. Use `scaler.fit_transform` to scale each column in `X_train` to standard normal. Save the scaled training dataset as `X_train_scaled`.\n",
        "3. Use `scaler.transform` to scale `X_test`. Save the scaled test dataset as `X_test_scaled`.\n",
        "4. Add a column to `X_train_scaled` with all 1s. Do the same thing for `X_test_scaled`.\n",
        "5. Print the types of objects `X_train_scaled` and `X_test_scaled`.\n",
        "6. Print the shapes of objects `X_train_scaled` and `X_test_scaled`.\n",
        "7. Print the first five rows of `X_train_scaled` and `X_test_scaled`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled = np.concatenate([X_train_scaled, np.ones((X_train_scaled.shape[0], 1))], axis=1)\n",
        "X_test_scaled = np.concatenate([X_test_scaled, np.ones((X_test_scaled.shape[0], 1))], axis=1)\n",
        "\n",
        "print(type(X_train_scaled))\n",
        "print(type(X_test_scaled))\n",
        "\n",
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "\n",
        "print(X_train_scaled[:5])\n",
        "print(X_test_scaled[:5])\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 10 (5 points, non-coding task)\n",
        "\n",
        "So far, we have finished preprocessing our dataset. We use this dataset for the purpose of doing binary classification.\n",
        "\n",
        "In all remaining parts in this problem, we will train a logistic regression model with our preprocessed data and test its performance.\n",
        "\n",
        "Let all training samples be indexed as $0, 1, \\cdots, N-1$. For the $n$th sample, denote by $\\mathbf{x}^{(n)} \\in \\mathbb{R}^{d \\times 1}$ a column vector of all features and $y^{(n)} \\in \\{0, 1\\}$ its ground-truth label.\n",
        "\n",
        "In the logistic regression, denote by $\\boldsymbol{\\beta} \\in \\mathbb{R}^{d \\times 1}$ the learnable parameters.\n",
        "\n",
        "Thus, our predicted label is determined according to:\n",
        "\n",
        "$$y^{(n)}_{\\text{predict}} = \\begin{cases} 1, & \\text{with probability } \\sigma \\left( \\mathbf{x}^{(n), \\top} \\boldsymbol{\\beta} \\right) \\\\ 0, & \\text{with probability } 1 - \\sigma \\left( \\mathbf{x}^{(n), \\top} \\boldsymbol{\\beta} \\right) \\end{cases}$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
        "\n",
        "is the sigmoid function.\n",
        "\n",
        "Do the following task in this part.\n",
        "\n",
        "To train our model, we need to solve the following optimization problem:\n",
        "\n",
        "$$\\min_{\\boldsymbol{\\beta}} \\ L(\\boldsymbol{\\beta})$$\n",
        "\n",
        "Write down the loss function $L(\\boldsymbol{\\beta})$ in the following form (reasoning is not required):\n",
        "\n",
        "$$L(\\boldsymbol{\\beta}) = \\sum_{n=0}^{N-1} \\cdots$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "$$L(\\boldsymbol{\\beta}) = \\sum_{n=0}^{N-1} -\\left( y^{(n)} \\log\\left( \\sigma\\left( \\mathbf{x}^{(n), \\top} \\boldsymbol{\\beta} \\right) \\right) + \\left(1 - y^{(n)}\\right) \\log\\left( 1 - \\sigma\\left( \\mathbf{x}^{(n), \\top} \\boldsymbol{\\beta} \\right) \\right) \\right)$$\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 11 (5 points, non-coding task)\n",
        "\n",
        "Compute\n",
        "\n",
        "$$\\frac{d \\sigma(z)}{dz}$$\n",
        "\n",
        "Express your answer using $\\sigma(z)$ only ($e^z$ or $e^{-z}$ should not appear in your final solution).\n",
        "\n",
        "Reasoning is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "We have\n",
        "\n",
        "$$\\frac{d \\sigma(z)}{dz} = \\frac{e^{-z}}{(1 + e^{-z})^2} = \\sigma(z)(1 - \\sigma(z))$$\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 12 (5 points, non-coding task)\n",
        "\n",
        "In this part, you are asked to compute $\\nabla_{\\boldsymbol{\\beta}} L(\\boldsymbol{\\beta})$ and express your solutions in two forms. Reasoning is not required.\n",
        "\n",
        "1. Write $\\nabla_{\\boldsymbol{\\beta}} L(\\boldsymbol{\\beta})$ in the following summation form:\n",
        "\n",
        "$$\\nabla_{\\boldsymbol{\\beta}} L(\\boldsymbol{\\beta}) = \\sum_{n=0}^{N-1} \\cdots$$\n",
        "\n",
        "2. Denote\n",
        "\n",
        "$$\\mathbf{X} = \\begin{bmatrix} \\mathbf{x}^{(0), \\top} \\\\ \\mathbf{x}^{(1), \\top} \\\\ \\vdots \\\\ \\mathbf{x}^{(N-1), \\top} \\end{bmatrix}$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\\mathbf{y} = \\begin{bmatrix} y^{(0)} \\\\ y^{(1)} \\\\ \\vdots \\\\ y^{(N-1)} \\end{bmatrix}$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\\mathbf{z} = \\begin{bmatrix} \\sigma \\left( \\mathbf{x}^{(0), \\top} \\boldsymbol{\\beta} \\right) \\\\ \\sigma \\left( \\mathbf{x}^{(1), \\top} \\boldsymbol{\\beta} \\right) \\\\ \\vdots \\\\ \\sigma \\left( \\mathbf{x}^{(N-1), \\top} \\boldsymbol{\\beta} \\right) \\end{bmatrix}$$\n",
        "\n",
        "Write $\\nabla_{\\boldsymbol{\\beta}} L(\\boldsymbol{\\beta})$ in terms of $\\mathbf{X}$, $\\mathbf{y}$, $\\mathbf{z}$ with matrix operations (the summation symbol is not allowed).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "We have\n",
        "\n",
        "$$\\nabla_{\\boldsymbol{\\beta}} L(\\boldsymbol{\\beta}) = \\sum_{n=0}^{N-1} \\left( \\sigma\\left( \\mathbf{x}^{(n), \\top} \\boldsymbol{\\beta} \\right) - y^{(n)} \\right) \\mathbf{x}^{(n)} = \\mathbf{X}^\\top (\\mathbf{z} - \\mathbf{y})$$\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 13 (5 points, non-coding task)\n",
        "\n",
        "In this part, you are asked to compute $\\nabla_{\\boldsymbol{\\beta}}^2 L(\\boldsymbol{\\beta})$ and express your solutions in two forms. Reasoning is not required.\n",
        "\n",
        "1. Write $\\nabla_{\\boldsymbol{\\beta}}^2 L(\\boldsymbol{\\beta})$ in the following summation form:\n",
        "\n",
        "$$\\nabla_{\\boldsymbol{\\beta}}^2 L(\\boldsymbol{\\beta}) = \\sum_{n=0}^{N-1} \\cdots$$\n",
        "\n",
        "2. Denote\n",
        "\n",
        "$$\\mathbf{Z} = \\begin{bmatrix} z_0 & 0 & \\cdots & 0 \\\\ 0 & z_1 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & 0 \\\\ 0 & 0 & \\cdots & z_{N-1} \\end{bmatrix}$$\n",
        "\n",
        "Write $\\nabla_{\\boldsymbol{\\beta}}^2 L(\\boldsymbol{\\beta})$ in terms of $\\mathbf{X}$, $\\mathbf{Z}$ with matrix operations (the summation symbol is not allowed).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "We have\n",
        "\n",
        "$$\\nabla_{\\boldsymbol{\\beta}}^2 L(\\boldsymbol{\\beta}) = \\sum_{n=0}^{N-1} \\sigma\\left( \\mathbf{x}^{(n), \\top} \\boldsymbol{\\beta} \\right) \\left( 1 - \\sigma\\left( \\mathbf{x}^{(n), \\top} \\boldsymbol{\\beta} \\right) \\right) \\mathbf{x}^{(n)} \\mathbf{x}^{(n), \\top} = \\mathbf{X}^\\top \\mathbf{Z} \\mathbf{X}$$\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 14 (5 points, non-coding task)\n",
        "\n",
        "Prove that $L(\\boldsymbol{\\beta})$ is a (weakly) concave function.\n",
        "\n",
        "Reasoning is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "Because $\\sigma(\\cdot) \\in [0, 1]$ and $\\mathbf{x}^{(n)} \\mathbf{x}^{(n), \\top}$ is a positive semidefinite matrix, we have that $\\nabla_{\\boldsymbol{\\beta}}^2 L(\\boldsymbol{\\beta})$ is a positive semidefinite matrix.\n",
        "\n",
        "Therefore, $L(\\boldsymbol{\\beta})$ is (weakly) concave.\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 15 (5 points, non-coding task)\n",
        "\n",
        "To learn $\\boldsymbol{\\beta}$, we do whole-batch iteration with the gradient descent algorithm and the Newton's method.\n",
        "\n",
        "In this part, denote by $\\eta > 0$ the learning rate.\n",
        "\n",
        "Do the following tasks in this part (reasoning is not required).\n",
        "\n",
        "1. Write down the gradient descent algorithm in the following form:\n",
        "\n",
        "$$\\boldsymbol{\\beta} \\leftarrow \\boldsymbol{\\beta} - \\eta \\cdot \\boxed{???}$$\n",
        "\n",
        "2. Write down the Newton's method in the following form:\n",
        "\n",
        "$$\\boldsymbol{\\beta} \\leftarrow \\boldsymbol{\\beta} - \\eta \\cdot \\boxed{???}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "$$\\boldsymbol{\\beta} \\leftarrow \\boldsymbol{\\beta} - \\eta \\cdot \\nabla_{\\boldsymbol{\\beta}} L(\\boldsymbol{\\beta})$$\n",
        "\n",
        "$$\\boldsymbol{\\beta} \\leftarrow \\boldsymbol{\\beta} - \\eta \\cdot \\left( \\nabla_{\\boldsymbol{\\beta}}^2 L(\\boldsymbol{\\beta}) \\right)^{-1} (\\nabla_{\\boldsymbol{\\beta}} L(\\boldsymbol{\\beta}))$$\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 16 (5 points, coding task)\n",
        "\n",
        "Define a function called `my_sigmoid`:\n",
        "\n",
        "- **Input:** A numpy array with any shape.\n",
        "- **Output:** Elementwise sigmoid functional values.\n",
        "\n",
        "No loop in the body of your function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "def my_sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 17 (15 points, coding task)\n",
        "\n",
        "Construct a class called `My_Log_Reg` whose objects are logistic regression models.\n",
        "\n",
        "### Method `__init__`\n",
        "\n",
        "**Inputs**\n",
        "- `solver`: The value must be `GD` or `Newton`. Otherwise, it raises an error message `Invalid solver`.\n",
        "- `lr`: The learning rate.\n",
        "- `num_iter`: The total number of iterations.\n",
        "\n",
        "**Attributes**\n",
        "- `solver`\n",
        "- `lr`\n",
        "- `num_iter`\n",
        "- `coef_`: $\\boldsymbol{\\beta}$ in our theoretical model. It shall be a 1-dim numpy array with shape `(d,)`.\n",
        "\n",
        "### Method `fit`\n",
        "\n",
        "**Inputs**\n",
        "- `X`: Features in a training dataset. The shape is `(N_train, d)`.\n",
        "- `y`: Ground-truth labels in a training dataset. The shape is `(N_train,)`.\n",
        "\n",
        "**In the body of this method**\n",
        "- Use the configured solver to compute `coef_`.\n",
        "- Do whole-batch iteration.\n",
        "- After finishing training `coef_`, generate a plot about the loss function vs iteration.\n",
        "  - The x-label is `iter`.\n",
        "  - The y-label is `loss`.\n",
        "  - The title is the optimization method: either `GD` or `Newton`.\n",
        "- The only loop that you can use is the whole-batch iteration. Within each iteration, when you update `coef_` by applying either GD or Newton, you are not allowed to use any loop.\n",
        "\n",
        "**Output**\n",
        "- `None`\n",
        "\n",
        "### Method `predict`\n",
        "\n",
        "**Input**\n",
        "- `X`: Features in a test dataset. The shape is `(N_test, d)`.\n",
        "\n",
        "**Output**\n",
        "- `y_pred`: Predicted labels in the test dataset. The shape is `(N_test,)`.\n",
        "\n",
        "### Method `score`\n",
        "\n",
        "**Input**\n",
        "- `X`: Features in a test dataset. The shape is `(N_test, d)`.\n",
        "- `y`: Ground-truth labels in the test dataset. The shape is `(N_test,)`.\n",
        "\n",
        "**Output**\n",
        "- `accuracy_score`: The accuracy score of the prediction of `y`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "class My_Log_Reg:\n",
        "    def __init__(self, solver, lr, num_iter):\n",
        "        self.solver = solver\n",
        "        self.lr = lr\n",
        "        self.num_iter = num_iter\n",
        "        self.coef_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        N, d = X.shape\n",
        "        self.coef_ = np.zeros(d)\n",
        "        loss_history = []\n",
        "        loss = -np.sum(y * np.log(my_sigmoid(X @ self.coef_)) + (1 - y) * np.log(1 - my_sigmoid(X @ self.coef_)))\n",
        "        loss_history.append(loss)\n",
        "\n",
        "        if self.solver == 'GD':\n",
        "            for i in range(self.num_iter):\n",
        "                params_grad = X.T @ (my_sigmoid(X @ self.coef_) - y)\n",
        "                self.coef_ -= self.lr * params_grad\n",
        "                loss = -np.sum(y * np.log(my_sigmoid(X @ self.coef_)) + (1 - y) * np.log(1 - my_sigmoid(X @ self.coef_)))\n",
        "                loss_history.append(loss)\n",
        "\n",
        "            plt.plot(loss_history)\n",
        "            plt.xlabel('iter')\n",
        "            plt.ylabel('loss')\n",
        "            plt.title('GD')\n",
        "            plt.show()\n",
        "        elif self.solver == 'Newton':\n",
        "            for i in range(self.num_iter):\n",
        "                params_grad = X.T @ (my_sigmoid(X @ self.coef_) - y)\n",
        "                params_Hessian = X.T @ np.diag(my_sigmoid(X @ self.coef_) * (1 - my_sigmoid(X @ self.coef_))) @ X\n",
        "                self.coef_ -= self.lr * np.linalg.inv(params_Hessian) @ params_grad\n",
        "                loss = -np.sum(y * np.log(my_sigmoid(X @ self.coef_)) + (1 - y) * np.log(1 - my_sigmoid(X @ self.coef_)))\n",
        "                loss_history.append(loss)\n",
        "\n",
        "            plt.plot(loss_history)\n",
        "            plt.xlabel('iter')\n",
        "            plt.ylabel('loss')\n",
        "            plt.title('Newton')\n",
        "            plt.show()\n",
        "        else:\n",
        "            raise ValueError('Invalid solver')\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = np.where(my_sigmoid(X @ self.coef_) >= 0.5, 1, 0)\n",
        "        return y_pred\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        accuracy_score = np.mean(y_pred == y)\n",
        "        return accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 18 (5 points, coding task)\n",
        "\n",
        "Do the following tasks in this problem.\n",
        "\n",
        "1. Define two models:\n",
        "   - `model_GD = My_Log_Reg(solver='GD', lr=.01, num_iter=200)`\n",
        "   - `model_Newton = My_Log_Reg(solver='Newton', lr=.1, num_iter=200)`\n",
        "\n",
        "2. For each model,\n",
        "   - Use the training dataset to train it.\n",
        "   - Print the trained coefficients `coef_`.\n",
        "   - Use the test dataset to compute the accuracy score. Print it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "model_GD = My_Log_Reg(solver='GD', lr=.001, num_iter=200)\n",
        "model_GD.fit(X_train_scaled, y_train)\n",
        "print(model_GD.coef_)\n",
        "print(model_GD.score(X_test_scaled, y_test))\n",
        "\n",
        "\n",
        "model_Newton = My_Log_Reg(solver='Newton', lr=.1, num_iter=200)\n",
        "model_Newton.fit(X_train_scaled, y_train)\n",
        "print(model_Newton.coef_)\n",
        "print(model_Newton.score(X_test_scaled, y_test))\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
