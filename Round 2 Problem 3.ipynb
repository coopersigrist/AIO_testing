{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2025 USA-NA-AIO Round 2, Problem 3\n",
        "\n",
        "## Problem 3 (100 points)\n",
        "\n",
        "In this problem, you are asked to study Contrastive Language-Image Pre-Training (CLIP), a powerful tool in multimodal AI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run code in this cell\n",
        "\n",
        "\"\"\"\n",
        "DO NOT MAKE ANY CHANGE IN THIS CELL.\n",
        "HINT: If something is not corrected installed, simply run this cell for few more times.\n",
        "\"\"\"\n",
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## $\\color{red}{\\text{WARNING !!!}}$\n",
        "\n",
        "Beyond importing libraries/modules/classes/functions in the following cell, you are **NOT** allowed to import anything else for the following purposes:\n",
        "\n",
        "- As a part of your final solution. For instance, if a problem asks you to build a model without using sklearn but you use it, then you will not earn points.\n",
        "\n",
        "- Temporarily import something to assist you to get a solution. For instance, if a problem asks you to manually compute eigenvalues but you temporarily use `np.linalg.eig` to get an answer and then delete your code, then you violate the rule.\n",
        "\n",
        "**Rule of thumb:** Each part has its particular purpose to intentionally test you something. Do not attempt to find a shortcut to circumvent the rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run code in this cell\n",
        "\n",
        "\"\"\"\n",
        "DO NOT MAKE ANY CHANGE IN THIS CELL.\n",
        "\"\"\"\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from transformers import BertTokenizer, BertModel, ViTModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "We will use flickr30k dataset to do image-language matching.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run code in this cell\n",
        "\n",
        "\"\"\"\n",
        "DO NOT MAKE ANY CHANGE IN THIS CELL.\n",
        "\"\"\"\n",
        "from datasets import load_dataset\n",
        "dataset_train = load_dataset(\"USAAIO/2025-Round2-Problem3\", split='train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 1 (5 points, coding task)\n",
        "\n",
        "Do the following tasks to explore the properties of `dataset_train`:\n",
        "\n",
        "1. `dataset_train` is a list-like object. Print the number of elements in it.\n",
        "\n",
        "2. Consider index `idx = 2025`. Print the type of `dataset_train[idx]`.\n",
        "\n",
        "3. Print all keys in `dataset_train[idx]`.\n",
        "\n",
        "4. Name the value associated with the key `image` as `image_PIL`. Print it.\n",
        "\n",
        "5. Convert `image_PIL` to a NumPy array object, called `image_np`. Print `image_np` and its shape.\n",
        "\n",
        "6. Display this image by using `plt.imshow`.\n",
        "\n",
        "7. Print the value associated with the key `alt_text`. Print its type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2 (5 points, coding task)\n",
        "\n",
        "This dataset is too big. In our contest, we only use a small portion with 1000 samples.\n",
        "\n",
        "To avoid introducing any bias, we will randomly select 1000 distinct samples.\n",
        "\n",
        "Use NumPy to randomly select 1000 sample indices.\n",
        "- Use the random seed number `2025` to generated randomized indices. After the generation is completed, reset the seed number back to `None`.\n",
        "- The name of the output is called `indices`. It must be a list that contains 1000 integer type (not numpy array integers) objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 4 (5 points, coding task)\n",
        "\n",
        "In this part, we preprocess image data.\n",
        "\n",
        "1. Your job is to create a tensor `images_pt` from `image_list` that has shape `(1000, 3, 224, 224)` and datatype `float64`.\n",
        "\n",
        "2. The data range is from -1 to 1.\n",
        "\n",
        "3. **Hint:** If `a` is a PIL object, then you can use `a.resize` to resize it.\n",
        "\n",
        "4. Print `images_pt.shape`.\n",
        "\n",
        "5. Print `images_pt.dtype`.\n",
        "\n",
        "6. Print `images_pt[5]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5 (5 points, non-coding task)\n",
        "\n",
        "Note that our final goal is to build a CLIP neural network. For the image data, we will use Vision Transformers (ViT) to extract image embeddings.\n",
        "\n",
        "With the above high level information, please explain the reasons behind the following things that you did in Part 4.\n",
        "\n",
        "1. Why the channel dimension is ahead of the height and width dimensions?\n",
        "\n",
        "2. Why the sizes of all images are normalized to (224, 224)?\n",
        "\n",
        "3. Why each pixel value is normalized between -1 and 1?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 6 (5 points, coding task)\n",
        "\n",
        "In this part, we preprocess text data `text_list`.\n",
        "\n",
        "1. Do tokenization with\n",
        "   ```python\n",
        "   tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "   ```\n",
        "\n",
        "2. Call\n",
        "   ```python\n",
        "   token_id_list = tokenizer(text_list)['input_ids']\n",
        "   ```\n",
        "\n",
        "3. Print `token_id_list`.\n",
        "4. Print the type of `token_id_list`.\n",
        "5. Print the length of `token_id_list`.\n",
        "6. Print `token_id_list[5]`.\n",
        "7. Print the type of `token_id_list[5]`.\n",
        "8. Print the type of `token_id_list[5][0]`.\n",
        "9. For each `idx`, convert `token_id_list[idx]` from the above type to a 1-dim tensor. That is, after this step, `token_id_list` is a list that consists of all 1-dim tensors.\n",
        "10. Print `token_id_list[5:7]`.\n",
        "11. Print the data type of `token_id_list[5][0]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 7 (5 points, non-coding task)\n",
        "\n",
        "This part follows Part 6.\n",
        "\n",
        "Do the following tasks.\n",
        "\n",
        "1. Explain why token lists of all samples begin with token ID 101.\n",
        "2. Explain why token lists of all samples end with token ID 102.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 8 (5 points, coding task)\n",
        "\n",
        "In this part, we prepare our CLIP dataset.\n",
        "\n",
        "1. Define class `MyDataset` that subclasses `Dataset`.\n",
        "   - **`__init__`**\n",
        "     - Inputs: `images_pt`, `token_id_list`.\n",
        "     - Attributes: Same as inputs.\n",
        "   - **`__len__`**\n",
        "     - Output: total number of samples.\n",
        "   - **`__getitem__`**\n",
        "     - Input: sample index `idx`\n",
        "     - Outputs: `images_pt[idx]`, `token_id_list[idx]`\n",
        "\n",
        "2. Define dataset `CLIP_dataset` that is an object of `MyDataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 9 (5 points, coding task)\n",
        "\n",
        "### Part 9.1\n",
        "\n",
        "Define your own collate function.\n",
        "\n",
        "The function name is `my_collate_fn`.\n",
        "\n",
        "**Padding**\n",
        "\n",
        "For text data, let the longest sample be with K tokens.\n",
        "\n",
        "Consider another text sample with L tokens satisfying L < K. Then, in addition to those L tokens, this sample is padded with K-L padding tokens whose values are 0.\n",
        "\n",
        "**Outputs**\n",
        "\n",
        "- `token_id_batch`. If the batch size is B and the longest sample in the text data has K tokens, then `token_id_batch` is a tensor with shape (B,K).\n",
        "\n",
        "- `attention_mask_batch`. This is a tensor that has shape (B,K). If a position is occupied by a non-padding token, its value is 1. Otherwise, if it is occupied by a padding token, its value is 0. Data types are int64.\n",
        "\n",
        "- `image_batch`. This is a tensor that has shape (B,3,224,224).\n",
        "\n",
        "### Part 9.2\n",
        "\n",
        "Define a DataLoader object called `CLIP_dataloader`.\n",
        "\n",
        "- Set `batch_size = 16`.\n",
        "\n",
        "- Set `shuffle = True`.\n",
        "\n",
        "- Use the collate function defined in Part 9.1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "# Part 9.1\n",
        "\n",
        "\n",
        "# Part 9.2\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 10 (5 points, non-coding task)\n",
        "\n",
        "In this part, you are asked to answer some questions about a CLIP model that you shall build in the next part.\n",
        "\n",
        "Write your answers in the text cell below.\n",
        "\n",
        "To get answers, you may need to run experimental code to better learn the ViT and Bert models.\n",
        "\n",
        "We only grade your answers in the text cell.\n",
        "\n",
        "\n",
        "**1. Image encoder**\n",
        "\n",
        "- Define `model_image = ViTModel.from_pretrained('google/vit-base-patch16-224')`. We use all blocks except the last pooler layer. That is, this ViT model has two outputs: with their key names as `last_hidden_state` and `pooler_output`. You should take the value associated with the key `last_hidden_state`.\n",
        "\n",
        "- From the last hidden state, we project from position 0 to a latent space with dimension `embedding_size` (e.g., 512). The output is called **image embedding**.\n",
        "\n",
        "\n",
        "**2. Text encoder**\n",
        "\n",
        "- Define `model_text = BertModel.from_pretrained('bert-base-uncased')`. We use all blocks except the last pooler layer. That is, this Bert model has two outputs: with their key names as `last_hidden_state` and `pooler_output`. You should take the value associated with the key `last_hidden_state`.\n",
        "\n",
        "- From the last hidden state, we project from position 0 to a latent space with dimension `embedding_size` (e.g., 512). The output is called **text embedding**.\n",
        "\n",
        "**Answer the following questions.** (Reasoning is required only for Question 3)\n",
        "\n",
        "1. Let `image_batch` be with shape `(B,3,224,224)`. What is the shape of `model_image(image_batch)['last_hidden_state']`?\n",
        "\n",
        "2. Let `token_id_batch` and `attention_mask_batch` be with shape `(B,L)`. What is the shape of `model_text(input_ids = token_id_batch, attention_mask = attention_mask_batch)['last_hidden_state']`?\n",
        "\n",
        "3. For both the image encoder and the text encoder, we project the last hidden state from position 0 to a latent space with the same dimension `embedding_size`.\n",
        "\n",
        "   3.1. Why do we add this additional out-projection layer?\n",
        "\n",
        "   3.2. Why this layer is added on position 0 only?\n",
        "\n",
        "   3.3. Why the output dimensions from these two encoders are the same?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### DO YOUR EXPERIMENTAL STUDY HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 11 (5 points, coding task)\n",
        "\n",
        "In this part, you are asked to build your CLIP model.\n",
        "\n",
        "- The class name is `MyCLIP`. It subclasses `nn.Module`.\n",
        "\n",
        "- **`__init__`:**\n",
        "\n",
        "    - It takes one input argument - the size of the final embedding of text and image data. Set its default value as 512.\n",
        "\n",
        "    - Attribute `log_tau` is the log of temperature. It is a learnable parameter. Its initial value follows the standard normal distribution.\n",
        "\n",
        "- **`__forward__`:**\n",
        "\n",
        "    - It returns two objects: image embedding, text embedding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 12 (5 points, non-coding task)\n",
        "\n",
        "Explain why we use $\\log \\tau$ as an attribute, not $\\tau$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 13 (5 points, coding task)\n",
        "\n",
        "Do the following tasks:\n",
        "\n",
        "1. Define your model by calling `model_CLIP = MyCLIP()`.\n",
        "\n",
        "2. Fix all parameter values in the ViT and Bert blocks in your model. That is, you are only allowed to train:\n",
        "   - Out-projection matrices in the image and text encoders.\n",
        "   - Temperature.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 14 (5 points, coding task)\n",
        "\n",
        "Do the following tasks:\n",
        "\n",
        "1. Set the learning rate as `1e-3`.\n",
        "\n",
        "2. Choose your optimization algorithm as Adam.\n",
        "\n",
        "3. Define an optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 15 (5 points, coding task)\n",
        "\n",
        "In this part, you are asked to define a loss function.\n",
        "\n",
        "Let $I_i$ and $T_j$ be image $i$'s embedding and text $j$'s embedding, respectively. Let $B$ be the batch size. Let $\\tau$ be the temperature.\n",
        "\n",
        "Then the loss function is defined as\n",
        "\n",
        "$$\\mathcal{L} = \\frac{1}{2} \\left( -\\frac{1}{B} \\sum_{i=0}^{B-1} \\log \\frac{\\exp(\\text{SIM}(I_i, T_i) / \\tau)}{\\sum_{j=0}^{B-1} \\exp(\\text{SIM}(I_i, T_j) / \\tau)} - \\frac{1}{B} \\sum_{i=0}^{B-1} \\log \\frac{\\exp(\\text{SIM}(I_i, T_i) / \\tau)}{\\sum_{j=0}^{B-1} \\exp(\\text{SIM}(I_j, T_i) / \\tau)} \\right),$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\\text{SIM}(I_i, T_j) = \\frac{I_i^\\top T_j}{\\|I_i\\|_2 \\|T_j\\|_2}.$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 16 (5 points, coding task)\n",
        "\n",
        "In this part, you are asked to train your model.\n",
        "\n",
        "1. Set the number of epochs as 100.\n",
        "\n",
        "2. Do training on GPU.\n",
        "\n",
        "3. For every epoch, print the average loss per sample in this epoch.\n",
        "\n",
        "4. You may use `tqdm` to track your progress and help you manage your time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "So far, we use the cosine function to measure the similarity between two vectors. Next, you are asked to do theoretical study of its reasonableness.\n",
        "\n",
        "Your task is to prove the following theorem.\n",
        "\n",
        "**Theorem:**\n",
        "\n",
        "Let $x, y \\in \\mathbb{R}^d$ be two independent $d$-dim vectors that follow the same multi-variate standard normal distribution $\\mathcal{N}(0_d, I_{d \\times d})$.\n",
        "\n",
        "Then for any $\\epsilon > 0$, when $d$ is large,\n",
        "\n",
        "$$P\\left( \\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2} > \\epsilon \\right) \\leq \\frac{1}{\\epsilon^2 d}.$$\n",
        "\n",
        "We prove this in multiple steps.\n",
        "\n",
        "---\n",
        "\n",
        "## Part 17 (5 points, non-coding task)\n",
        "\n",
        "First, you are asked to prove the following lemma.\n",
        "\n",
        "**Lemma 1:**\n",
        "\n",
        "If $x \\sim \\mathcal{N}(0_d, I_{d \\times d})$, then for any unit vector $\\hat{e} \\in \\mathbb{R}^d$,\n",
        "\n",
        "$$\\hat{e}^\\top x \\sim \\mathcal{N}(0, 1).$$\n",
        "\n",
        "That is, the projection of $x$ onto $\\hat{e}$ is a standard normal random variable.\n",
        "\n",
        "**Hint:** You can directly use the result that $\\hat{e}^\\top x$ is normal. Therefore, you only need to prove that $\\hat{e}^\\top x$ has mean 0 and variance 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 18 (5 points, non-coding task)\n",
        "\n",
        "Lemma 1 implies that the projection of $x$ onto any direction is a standard normal. Therefore, all directions are homogeneous.\n",
        "\n",
        "Therefore,\n",
        "\n",
        "$$P\\left( \\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2} > \\epsilon \\right) = P\\left( \\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2} > \\epsilon \\mid x = \\hat{x} \\right), \\quad \\forall \\hat{x} \\in \\mathbb{R}^d.$$\n",
        "\n",
        "For simplicity, we consider\n",
        "\n",
        "$$\\hat{x} = \\begin{bmatrix} 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} \\in \\mathbb{R}^d.$$\n",
        "\n",
        "Therefore, we only need to bound\n",
        "\n",
        "$$P\\left( \\frac{y_0}{\\|y\\|_2} > \\epsilon \\right)$$\n",
        "\n",
        "By symmetry, it is easy to see that\n",
        "\n",
        "$$\\mathbb{E}\\left[ \\frac{y_0}{\\|y\\|_2} \\right] = 0.$$\n",
        "\n",
        "Hence, we get\n",
        "\n",
        "$$P\\left( \\frac{y_0}{\\|y\\|_2} > \\epsilon \\right) \\leq \\frac{\\text{Var}\\left[ \\frac{y_0}{\\|y\\|_2} \\right]}{\\epsilon^2} = \\frac{\\mathbb{E}\\left[ \\frac{y_0^2}{\\|y\\|_2^2} \\right]}{\\epsilon^2}$$\n",
        "\n",
        "$$= \\frac{1}{\\epsilon^2 d} \\mathbb{E}\\left[ \\frac{y_0^2}{\\frac{1}{d} \\sum_{i=0}^{d-1} y_i^2} \\right]$$\n",
        "\n",
        "where the first inequality follows from the Chebyshev's inequality.\n",
        "\n",
        "To prove the theorem, it is equivalent to prove the following lemma.\n",
        "\n",
        "**Lemma 2:**\n",
        "\n",
        "Let $y_0, \\cdots, y_{d-1}$ be identically and independent variables that are all standard normals. Then for large $d$,\n",
        "\n",
        "$$\\mathbb{E}\\left[ \\frac{y_0^2}{\\frac{1}{d} \\sum_{i=0}^{d-1} y_i^2} \\right] \\approx 1.$$\n",
        "\n",
        "In this part, your task is to prove this lemma.\n",
        "\n",
        "**Hint:** It is hard to prove this statement in an exact way. You can make any reasonable approximation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 19 (5 points, non-coding task)\n",
        "\n",
        "Lemmas 1 and 2 jointly imply the theorem above. Please use the result in this theorem to explain why it is reasonable to use the cosine function to measure similarity of two embedding vectors and why the latent space needs to be high dimensional (such as 512, 768, 1024).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 20 (5 points, non-coding task)\n",
        "\n",
        "In the loss function, we introduced a crutial learnable parameter $\\tau$, called temperature.\n",
        "\n",
        "Let us explore some properties of $\\tau$.\n",
        "\n",
        "Let $z_0 > z_1 > \\cdots > z_{N-1}$.\n",
        "\n",
        "Define\n",
        "\n",
        "$$f_i = \\frac{\\exp(z_i / \\tau)}{\\sum_{j=0}^{N-1} \\exp(z_j / \\tau)}.$$\n",
        "\n",
        "Do the following analysis. Reasoning is required.\n",
        "\n",
        "1. Compute $\\lim_{\\tau \\to 0^+} f_i$.\n",
        "\n",
        "2. Compute $\\lim_{\\tau \\to \\infty} f_i$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
