{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIO Q1 -- Word2Vec Skip-Gram with Negative Sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In the Word2Vec skip-gram model, the goal is to predict **context words** given a **center word**.\n",
    "Each word has two embeddings:\n",
    "\n",
    "- **Input embedding** from matrix $U \\in \\mathbb{R}^{V \\times d}$  \n",
    "- **Output embedding** from matrix $W \\in \\mathbb{R}^{V \\times d}$\n",
    "\n",
    "Where:\n",
    "- $V$ = vocabulary size (total number of unique words)\n",
    "- $d$ = embedding dimension (vector size for each word)\n",
    "- $K$ = number of negative samples per positive pair\n",
    "\n",
    "The negative sampling loss for one training pair is:\n",
    "\n",
    "$$\n",
    "L = -\\log \\sigma(s_{\\text{pos}}) - \\sum_{k=1}^K \\log \\sigma(-s_{\\text{neg},k})\n",
    "$$\n",
    "\n",
    "Where $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ is the sigmoid function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy is the only library you'll need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 — Understanding Separate Embedding Matrices [8 points]\n",
    "\n",
    "### 1.1 [3 points]\n",
    "**Explain** why the operation $u_c = U[c]$ (selecting row $c$ from $U \\in \\mathbb{R}^{V \\times d}$) requires $O(d)$ time rather than $O(Vd)$ time.\n",
    "\n",
    "Your explanation should mention:\n",
    "- How rows are stored in memory\n",
    "- Why we don't need to examine all $V$ rows\n",
    "</br></br>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 [5 points]\n",
    "Let $\\mathcal{M}_{\\text{share}}$ denote a model using one shared embedding matrix and $\\mathcal{M}_{\\text{separate}}$ denote a model using separate $U$ and $W$ matrices.\n",
    "\n",
    "**Show** that $\\mathcal{M}_{\\text{separate}}$ has strictly more representational capacity by constructing a counterexample: Give specific $2 \\times 2$ matrices $U$ and $W$ and demonstrate a configuration that cannot be represented by any single shared matrix.\n",
    "</br></br>\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 — Properties of the Dot Product Score [12 points]\n",
    "\n",
    "The compatibility score is $s = w_o^\\top u_c = \\sum_{i=1}^d w_{o,i} \\cdot u_{c,i}$.\n",
    "\n",
    "### 2.1 [6 points]\n",
    "**Prove** or **disprove** the following statement:\n",
    "\n",
    "> *\"If $\\|u_c\\|_2 = \\|w_o\\|_2 = 1$ (unit vectors), then $s \\in [-1, 1]$.\"*\n",
    "\n",
    "If true, provide a proof. If false, provide a counterexample.\n",
    "</br></br>\n",
    "**Answer:**\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 [6 points]\n",
    "Suppose all embeddings are initialized from $\\mathcal{N}(0, \\sigma^2)$ where $\\sigma = 0.01$ and $d = 300$.\n",
    "\n",
    "**Compute** the expected value and variance of the dot product $s = w_o^\\top u_c$ at initialization, assuming $u_c$ and $w_o$ are independent.\n",
    "\n",
    "**Given**: For independent random variables $X \\sim \\mathcal{N}(0, \\sigma_X^2)$ and $Y \\sim \\mathcal{N}(0, \\sigma_Y^2)$:\n",
    "- $\\mathbb{E}[XY] = 0$\n",
    "- $\\text{Var}(XY) = \\sigma_X^2 \\sigma_Y^2$\n",
    "\n",
    "</br></br>\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 — Sigmoid Function Analysis [10 points]\n",
    "\n",
    "### 3.1 [5 points]\n",
    "**Prove** that:\n",
    "\n",
    "$$\n",
    "\\lim_{x \\to \\infty} \\sigma(x) = 1 \\quad \\text{and} \\quad \\lim_{x \\to -\\infty} \\sigma(x) = 0\n",
    "$$\n",
    "\n",
    "using the definition $\\sigma(x) = \\frac{1}{1 + e^{-x}}$.\n",
    "</br></br>\n",
    "**Answer:**\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 [5 points]\n",
    "**Derive** the derivative $\\frac{d\\sigma}{dx}$ and express it in terms of $\\sigma(x)$ itself.\n",
    "\n",
    "Show your work using the quotient rule or chain rule.\n",
    "\n",
    "</br></br>\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 — Computational Complexity Analysis [10 points]\n",
    "\n",
    "### 4.1 [5 points]\n",
    "Let $W \\in \\mathbb{R}^{V \\times d}$ and $u_c \\in \\mathbb{R}^d$.\n",
    "\n",
    "**Determine** the computational complexity of computing all scores $s = Wu_c$ (returning a vector of length $V$).</br> Express your answer in $\\Theta(\\cdot)$ notation and explain your reasoning.\n",
    "</br></br>\n",
    "**Answer:**\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 [5 points]\n",
    "During negative sampling, we only need $K+1$ scores (1 positive, $K$ negative) where $K \\ll V$.\n",
    "\n",
    "**Compute** the exact number of floating-point operations (multiplications + additions) needed for:\n",
    "1. Computing only the needed $K+1$ scores\n",
    "2. Computing the full matrix-vector product $Wu_c$\n",
    "\n",
    "Evaluate for $V = 200{,}000$, $d = 300$, $K = 10$.\n",
    "</br></br>\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 — Vectorized Loss Implementation [20 points]\n",
    "\n",
    "Complete the vectorized implementation with **no Python loops**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def neg_sampling_loss(U, W, c, o, negs):\n",
    "    \"\"\"\n",
    "    Compute: L = -log σ(s_pos) - Σ_k log σ(-s_neg,k)\n",
    "    \n",
    "    Args:\n",
    "        U: (V, d) center embeddings\n",
    "        W: (V, d) context embeddings\n",
    "        c: int, center word index\n",
    "        o: int, positive context word index\n",
    "        negs: (K,) negative sample indices\n",
    "    Returns:\n",
    "        loss: scalar\n",
    "    \"\"\"\n",
    "    u_c = U[c]          # (d,)\n",
    "    w_o = W[o]          # (d,)\n",
    "    w_negs = W[negs]    # (K, d)\n",
    "    \n",
    "    # Scores (provided)\n",
    "    s_pos = w_o @ u_c                 # scalar\n",
    "    s_negs = w_negs @ u_c             # (K,)\n",
    "\n",
    "    # --- Your code below (3–4 lines) ---\n",
    "    sig_pos = ...\n",
    "    sig_negs = ...\n",
    "    loss = ...\n",
    "    # -----------------------------------\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 — Vectorized Gradient Update Implementation [30 points]\n",
    "\n",
    "The gradients for negative sampling loss are:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial u_c} = (\\sigma(s_{\\text{pos}}) - 1) w_o + \\sum_{k=1}^K \\sigma(s_{\\text{neg},k}) w_{\\text{neg},k}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_o} = (\\sigma(s_{\\text{pos}}) - 1) u_c\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{\\text{neg},k}} = \\sigma(s_{\\text{neg},k}) u_c\n",
    "$$\n",
    "\n",
    "where $s_{\\text{pos}} = w_o^\\top u_c$ and $s_{\\text{neg},k} = w_{\\text{neg},k}^\\top u_c$.\n",
    "\n",
    "### 6.1 [30 points]\n",
    "Implement the gradient descent update:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_sampling_update(U, W, c, o, negs, lr):\n",
    "    \"\"\"\n",
    "    Perform gradient descent: θ ← θ - η·∇L\n",
    "    \n",
    "    Args:\n",
    "        U: (V, d) center embeddings (modified in place)\n",
    "        W: (V, d) context embeddings (modified in place)\n",
    "        c: int, center word index\n",
    "        o: int, positive context word index\n",
    "        negs: (K,) negative sample indices\n",
    "        lr: float, learning rate η\n",
    "    \"\"\"\n",
    "    # Step 1: Extract embeddings\n",
    "    u_c = U[c]          # (d,)\n",
    "    w_o = W[o]          # (d,)\n",
    "    w_negs = W[negs]    # (K, d)\n",
    "    \n",
    "    # Step 2: Compute scores\n",
    "    # s_pos = \n",
    "    # s_negs = \n",
    "    \n",
    "    # Step 3: Compute sigmoid values\n",
    "    # sig_pos = \n",
    "    # sig_negs = \n",
    "    \n",
    "    # Step 4: Compute gradients\n",
    "    # grad_u_c = \n",
    "    # grad_w_o = \n",
    "    # grad_w_negs = \n",
    "    \n",
    "    # Step 5: Update embeddings (gradient descent)\n",
    "    # U[c] -= \n",
    "    # W[o] -= \n",
    "    # W[negs] -= \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 — Sampling Distribution Analysis [10 points]\n",
    "\n",
    "Word2Vec uses $P_n(w) \\propto f(w)^{\\alpha}$ where $f(w)$ is word frequency and $\\alpha = 3/4$.\n",
    "\n",
    "### 7.1 [5 points]\n",
    "Let $R(\\alpha)$ be the ratio of sampling probabilities between a high-frequency word ($f_h = 0.05$) and a low-frequency word ($f_l = 0.00001$):\n",
    "\n",
    "$$\n",
    "R(\\alpha) = \\frac{P_n(w_h)}{P_n(w_l)} = \\left(\\frac{f_h}{f_l}\\right)^{\\alpha}\n",
    "$$\n",
    "\n",
    "**Compute** $R(1)$, $R(3/4)$, and $R(0)$.\n",
    "Show your calculations.\n",
    "</br></br>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "---\n",
    "\n",
    "### 7.2 [5 points]\n",
    "**Prove** that for any $0 < \\alpha < 1$ and frequencies $f_1 > f_2 > 0$:\n",
    "\n",
    "$$\n",
    "\\left(\\frac{f_1}{f_2}\\right)^{\\alpha} < \\frac{f_1}{f_2}\n",
    "$$\n",
    "\n",
    "**Interpret** this result: Why does using $\\alpha = 3/4$ instead of $\\alpha = 1$ help with the rare word problem?\n",
    "</br></br>\n",
    "**Answer:**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
