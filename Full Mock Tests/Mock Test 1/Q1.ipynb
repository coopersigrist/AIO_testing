{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de19aa15",
   "metadata": {},
   "source": [
    "# AIO Q1 — Noise Augmentation and Regularization\n",
    "\n",
    "We study linear regression under input noise augmentation.\n",
    "\n",
    "Model (scalar):\n",
    "\n",
    "$$\n",
    "y = f_\\theta(x) = \\theta x, \\qquad\n",
    "L(\\theta) = \\mathbb{E}[(y - \\theta x)^2]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0d43c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Q1 — Forward: Exponentials\n",
    "\n",
    "Starting from\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\mathbb{E}[(y - \\theta x)^2],\n",
    "$$\n",
    "\n",
    "**expand** into terms involving $\\mathbb{E}[y^2]$, $\\mathbb{E}[xy]$, and $\\mathbb{E}[x^2]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e7662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e6ebde4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Q2 — Define Augmented Loss (Scalar)\n",
    "\n",
    "We introduce *noise augmentation* on the input:\n",
    "\n",
    "$$\n",
    "x' = x + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2), \\quad \\epsilon \\perp (x, y).\n",
    "$$\n",
    "\n",
    "We train on noisy inputs using the augmented loss:\n",
    "\n",
    "$$\n",
    "L_{\\text{aug}}(\\theta) = \\mathbb{E}_{x, y, \\epsilon}\\!\\left[(y - \\theta x')^2\\right]\n",
    "$$\n",
    "\n",
    "**Expand** this loss into $\\mathbb{E}[y^2]$, $\\mathbb{E}[xy]$, $\\mathbb{E}[x^2]$, and $\\sigma^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b66609b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcc7f510",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Q3 — Simplify and Compare (Scalar)\n",
    "\n",
    "Show that\n",
    "\n",
    "$$\n",
    "L_{\\text{aug}}(\\theta) = L(\\theta) + \\theta^2 \\sigma^2\n",
    "$$\n",
    "\n",
    "**Question:**  \n",
    "What does this additional $\\theta^2 \\sigma^2$ term represent *intuitively*?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0819ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b42794",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Q4 — The Minimizer (Scalar)\n",
    "\n",
    "Find the minimizer $\\theta^\\star$ for:\n",
    "\n",
    "1. $L(\\theta)$  \n",
    "2. $L_{\\text{aug}}(\\theta)$\n",
    "\n",
    "**Compare:** How does noise augmentation affect the learned coefficient?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d813b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e670429",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Q5 — Regularization Connection (Scalar)\n",
    "\n",
    "Ridge regression minimizes\n",
    "\n",
    "$$\n",
    "L_{\\text{ridge}}(\\theta) = \\mathbb{E}[(y - \\theta x)^2] + \\lambda \\theta^2\n",
    "$$\n",
    "\n",
    "**Show:** $L_{\\text{aug}}(\\theta)$ can be written in this form and **identify** the effective $\\lambda$ in terms of $\\sigma^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399963e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e028cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Q6 — Multivariate Augmentation\n",
    "\n",
    "Now consider $d$-dimensional linear regression:\n",
    "\n",
    "$$\n",
    "y = w^\\top x, \\quad x \\in \\mathbb{R}^d,\n",
    "$$\n",
    "\n",
    "and augment inputs as $x' = x + \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_d)$, independent of $(x, y)$.\n",
    "\n",
    "We train on $x'$ by minimizing\n",
    "\n",
    "$$\n",
    "L_{\\text{aug}}(w) = \\mathbb{E}[(y - w^\\top x')^2]\n",
    "$$\n",
    "\n",
    "**Show that**\n",
    "\n",
    "$$\n",
    "L_{\\text{aug}}(w) = L(w) + \\sigma^2 \\|w\\|_2^2,\n",
    "$$\n",
    "\n",
    "where $L(w) = \\mathbb{E}[(y - w^\\top x)^2]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb42a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5728bd7",
   "metadata": {},
   "source": [
    "## Q7 — Empirical Verification of the Ridge Connection (clarified)\n",
    "\n",
    "**Goal:**  \n",
    "Verify numerically that *input noise* acts like an $\\ell_2$ (ridge) penalty.\n",
    "\n",
    "### Data-Generating Process (DGP)\n",
    "\n",
    "We start from a clean linear relationship with output (label) noise:\n",
    "\n",
    "$$\n",
    "x_i \\sim \\mathcal{N}(0,1), \\quad\n",
    "\\eta_i \\sim \\mathcal{N}(0, 0.5^2), \\quad\n",
    "y_i = 2x_i + \\eta_i,\n",
    "$$\n",
    "\n",
    "for $i = 1, \\dots, n$ with $n = 400$.\n",
    "\n",
    "- The dataset $(x, y)$ is fixed across all experiments.  \n",
    "- Random seed should be fixed for reproducibility.\n",
    "\n",
    "### Input Noise Augmentation\n",
    "\n",
    "For each $\\sigma \\in \\{0, 0.5, 1, 1.5, 2\\}$:\n",
    "\n",
    "1. Draw independent input noise  \n",
    "   $$\n",
    "   \\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2), \\quad \\epsilon_i \\perp (x_i, \\eta_i)\n",
    "   $$\n",
    "2. Form noisy inputs  \n",
    "   $$\n",
    "   x'_i = x_i + \\epsilon_i\n",
    "   $$\n",
    "3. Fit a **no-intercept linear model** using the closed-form least-squares estimator:\n",
    "   $$\n",
    "   \\hat{\\theta}(\\sigma) = \\frac{\\sum_i x'_i y_i}{\\sum_i (x'_i)^2}\n",
    "   $$\n",
    "\n",
    "### Experiment Steps\n",
    "\n",
    "1. Compute $\\hat{\\theta}(\\sigma)$ for each noise level.  \n",
    "2. Plot $\\hat{\\theta}$ versus $\\sigma$.  \n",
    "3. Overlay the theoretical curve $\\theta_{\\text{pop}}(\\sigma) = 2/(1+\\sigma^2)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf8f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05bd7ccf",
   "metadata": {},
   "source": [
    "## Q8 — Compare Augmentation to Explicit Ridge Regularization\n",
    "\n",
    "**Goal:** Show that training with noise is equivalent to explicit $\\ell_2$ regularization.\n",
    "\n",
    "Let $(x_i, y_i)_{i=1}^n$ be any fixed dataset (you may use any dataset available to you).\n",
    "\n",
    "**Steps**\n",
    "1. For $\\lambda \\in \\{0, 0.25, 0.5, 1, 2\\}$, fit the ridge estimator (no intercept):\n",
    "   $$\n",
    "   \\hat{\\theta}_{\\text{ridge}}(\\lambda)\n",
    "   = \\frac{\\sum_i x_i y_i}{\\sum_i x_i^2 + \\lambda}\n",
    "   $$\n",
    "2. For the same values, set $\\sigma^2 = \\lambda$ and perform *noise-augmented* training by replacing inputs with\n",
    "   $x_i' = x_i + \\epsilon_i$, where $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$, independent of $(x_i, y_i)$, and then compute\n",
    "   $$\n",
    "   \\hat{\\theta}_{\\text{aug}}(\\sigma^2)\n",
    "   = \\frac{\\sum_i x_i' y_i}{\\sum_i (x_i')^2}\n",
    "   $$\n",
    "3. Plot both $\\hat{\\theta}_{\\text{ridge}}$ and $\\hat{\\theta}_{\\text{aug}}$ as functions of $\\lambda$.\n",
    "\n",
    "**Question.** Do the two curves coincide numerically? If not exactly, what do you think may explain small discrepancies?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac386b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5c6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcaf1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
