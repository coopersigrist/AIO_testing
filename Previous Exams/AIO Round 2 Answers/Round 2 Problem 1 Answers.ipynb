{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2025 USA-NA-AIO Round 2, Problem 1 â€” ANSWERS\n",
        "\n",
        "## Problem 1 (100 points)\n",
        "\n",
        "Many physics systems are governed by the following type of partial differential equations (PDEs)\n",
        "\n",
        "$$F \\left( t, \\mathbf{r}, u, u_t, u_{tt}, \\nabla_{\\mathbf{r}} u, \\nabla^2_{\\mathbf{r}} u \\right) = 0 , \\ \\forall \\ t \\in \\left[ 0 , T \\right], \\ \\mathbf{r} \\in \\mathcal S$$\n",
        "\n",
        "where\n",
        "\n",
        "- $t \\in \\mathbb{R}$: Time.\n",
        "- $\\mathbf{r} \\in \\mathbb{R}^3$: Position.\n",
        "- $u \\left( t, \\mathbf{r} \\right) \\in \\mathbb{R}$: A function of $t$ and $\\mathbf{r}$ that is differentiable.\n",
        "- $u_t$: $\\frac{\\partial u}{\\partial t}$.\n",
        "- $u_{tt}$: $\\frac{\\partial^2 u}{\\partial t^2}$.\n",
        "- $\\mathcal S$: A convex set in $\\mathbb{R}^3$.\n",
        "\n",
        "For such a physics system, if we know\n",
        "\n",
        "**Initial condition (IC)**\n",
        "- $u \\left( 0, \\mathbf{r} \\right)$ for all $\\mathbf{r} \\in \\mathcal S$.\n",
        "- $u_t \\left( 0, \\mathbf{r} \\right)$ for all $\\mathbf{r} \\in \\mathcal S$ (This term is required if $u_{tt}$ appears in $F$. Otherwise, it is not needed.).\n",
        "\n",
        "**Boundary condition (BC)**\n",
        "- $u \\left( t, \\mathbf{r} \\right)$ for all $t \\in \\left[ 0 , T \\right]$ and $\\mathbf{r} \\in \\text{Boundary} \\left( \\mathcal S \\right)$.\n",
        "\n",
        "Then the value of $u \\left( t , \\mathbf{r} \\right)$ for any $t \\in \\left[ 0 , T \\right]$ and $\\mathbf{r} \\in \\mathcal S$ is uniquely determined.\n",
        "\n",
        "However, many such systems do not admit closed-form solutions. The canonical approach of discretizing a PDE to find numeric solutions has many limitations.\n",
        "\n",
        "To avoid those challenges, in this problem, you are asked to use the deep neural network approach to solve a physics-informed PDE, hereafter called as **Physics-Informed Neural Network (PINN)**.\n",
        "\n",
        "---\n",
        "\n",
        "In this problem, let us consider the following specific 1-dim thermal system:\n",
        "\n",
        "- A 1-dim rod with unit length.\n",
        "- The thermal diffusivity is $\\alpha > 0$.\n",
        "- Two endpoints of the rod are connected to two heat reservoirs whose temperatures are constant and normalized as 0.\n",
        "- At time $t = 0$, the temperature distribution on the rod follows a sinusoidal pattern.\n",
        "\n",
        "Denote by $u \\left( t, x \\right)$ the temperature at time $t$ on position $x$ in the rod.\n",
        "\n",
        "Thus, $u \\left( t, x \\right)$ satisfies:\n",
        "\n",
        "**PDE**\n",
        "\n",
        "$$u_t - \\alpha u_{xx} = 0 , \\ x \\in \\left[ 0, 1 \\right] , \\ t \\in \\left[ 0, 1 \\right]$$\n",
        "\n",
        "where\n",
        "- $u_t$: $\\frac{\\partial u}{\\partial t}$.\n",
        "- $u_x$: $\\frac{\\partial u}{\\partial x}$.\n",
        "- $u_{xx}$: $\\frac{\\partial^2 u}{\\partial x^2}$.\n",
        "\n",
        "**IC**\n",
        "\n",
        "$$u \\left( 0, x \\right) = \\sin \\left( \\pi x \\right) , \\ \\forall \\ x \\in \\left[ 0, 1 \\right]$$\n",
        "\n",
        "**BC**\n",
        "\n",
        "$$u \\left( t, 0 \\right) = u \\left( t, 1 \\right) = 0 , \\ \\forall \\ t \\in \\left[ 0, 1 \\right]$$\n",
        "\n",
        "Before starting this problem, make sure to run the following code first without any change:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## $\\color{red}{\\text{WARNING !!!}}$\n",
        "\n",
        "Beyond importing libraries/modules/classes/functions in the preceding cell, you are **NOT** allowed to import anything else for the following purposes:\n",
        "\n",
        "- As a part of your final solution. For instance, if a problem asks you to build a model without using sklearn but you use it, then you will not earn points.\n",
        "\n",
        "- Temporarily import something to assist you to get a solution. For instance, if a problem asks you to manually compute eigenvalues but you temporarily use `np.linalg.eig` to get an answer and then delete your code, then you violate the rule.\n",
        "\n",
        "**Rule of thumb:** Each part has its particular purpose to intentionally test you something. Do not attempt to find a shortcut to circumvent the rule.\n",
        "\n",
        "All coding tasks shall run on **CPUs, not GPUs**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 1 (10 points, non-coding task)\n",
        "\n",
        "Prove that the solution to the above PDE, IC, and BC takes the following form:\n",
        "\n",
        "$$u \\left( t, x \\right) = e^{- \\alpha \\pi^2 t} \\sin \\left( \\pi x \\right)$$\n",
        "\n",
        "Reasoning is required.\n",
        "\n",
        "This part is used for the purpose of verifying the correctness of our subsequent PINN solution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "First, we have\n",
        "\n",
        "$$u_t(t, x) = -\\alpha \\pi^2 u(t, x)$$\n",
        "\n",
        "and\n",
        "\n",
        "$$u_{xx}(t, x) = -\\pi^2 u(t, x)$$\n",
        "\n",
        "Hence, $u(t, x)$ satisfies the PDE.\n",
        "\n",
        "Second,\n",
        "\n",
        "$$u(0, x) = \\sin(\\pi x)$$\n",
        "\n",
        "Hence, $u(t, x)$ satisfies the IC.\n",
        "\n",
        "Third,\n",
        "\n",
        "$$u(t, 0) = u(t, 1) = 0$$\n",
        "\n",
        "Hence, $u(t, x)$ satisfies the BC.\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "The high level idea of PINN is as follows:\n",
        "\n",
        "**(Neural network)** We design a neural network (functional mapping) $U(\\cdot, \\cdot \\mid \\theta): [0,1]^2 \\to \\mathbb{R}$, such that\n",
        "- $\\theta$: learnable parameters in $U$.\n",
        "- Inputs are time $t$ and position $x$.\n",
        "- Output is the predicted temperature.\n",
        "\n",
        "**(Training data)** To train $U$ (equivalently, to learn $\\theta$), we use the following three groups of temporal-spacial data $(t, x)$:\n",
        "- **(Training data for PDE)** $(t, x)$ are randomly sampled from $[0,1]^2$. Denote by $\\mathcal{D}_{PDE}$ the set of these data points.\n",
        "- **(Training data for IC)** $(0, x)$ with $x$ that are evenly distributed on $[0, 1]$. Denote by $\\mathcal{D}_{IC}$ the set of these data points.\n",
        "- **(Training data for BC)** $(t, 0)$ and $(t, 1)$ with $t$ that are evenly distributed on $[0, 1]$. Denote by $\\mathcal{D}_{BC}$ the set of these data points.\n",
        "\n",
        "**(Loss function in training)**\n",
        "\n",
        "$$L_{total} = L_{PDE} + L_{IC} + L_{BC}$$\n",
        "\n",
        "where\n",
        "\n",
        "**Residual loss in PDE:**\n",
        "\n",
        "$$L_{PDE} = \\frac{1}{|\\mathcal{D}_{PDE}|} \\sum_{(t,x) \\in \\mathcal{D}_{PDE}} \\left( \\frac{\\partial U(t, x \\mid \\theta)}{\\partial t} - \\alpha \\frac{\\partial^2 U(t, x \\mid \\theta)}{\\partial x^2} \\right)^2$$\n",
        "\n",
        "**IC loss:**\n",
        "\n",
        "$$L_{IC} = \\frac{1}{|\\mathcal{D}_{IC}|} \\sum_{(t,x) \\in \\mathcal{D}_{IC}} \\left( U(t, x \\mid \\theta) - u(t, x) \\right)^2$$\n",
        "\n",
        "**BC loss:**\n",
        "\n",
        "$$L_{BC} = \\frac{1}{|\\mathcal{D}_{BC}|} \\sum_{(t,x) \\in \\mathcal{D}_{BC}} \\left( U(t, x \\mid \\theta) - u(t, x) \\right)^2$$\n",
        "\n",
        "---\n",
        "\n",
        "## Part 2 (10 points, coding task)\n",
        "\n",
        "In this part, you are asked to build a deep neural network that is used to output PDE solutions.\n",
        "\n",
        "1. The class name is `HeatPINN`.\n",
        "    - It subclasses `nn.Module`.\n",
        "2. The model consists of the following layers that are sequentially connected:\n",
        "    1. Fully connected layer with `out_features = 64` (you need to determine `in_features` taken from the input).\n",
        "    2. Activation layer with `tanh` function.\n",
        "    3. Fully connected layer with `in_features = 64` and `out_features = 64`.\n",
        "    4. Activation layer with `tanh` function.\n",
        "    5. Fully connected layer with `in_features = 64` (you need to determine `out_features` as the output of the entire model).\n",
        "\n",
        "3. Construct a model who is an object of this class and is called as `model`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "class HeatPINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = HeatPINN()\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 3 (5 points, coding task)\n",
        "\n",
        "Do the following tasks:\n",
        "\n",
        "Let `x` be a tensor with shape `(N, 2)`.\n",
        "1. What is the number of dimensions of `model(x)`?\n",
        "2. What is the shape of `model(x)`?\n",
        "3. Explain the reasoning of your answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "1. The dimension of `model(x)` is 2.\n",
        "\n",
        "2. The shape of `model(x)` is `(N, 1)`.\n",
        "\n",
        "3. For each sample, the output is a 1-dim tensor with shape `(1,)`. Therefore, by having N samples, we get the answers above.\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 4 (10 points, coding task)\n",
        "\n",
        "In this part, you are asked to create the dataset $\\mathcal{D}_{PDE}$.\n",
        "\n",
        "1. The dataset object is called `dataset_train_PDE`. It is in a class called `Dataset_PDE` that you need to build.\n",
        "2. Class `Dataset_PDE` subclasses `Dataset`.\n",
        "3. Each $(t, x) \\in \\mathcal{D}_{PDE}$ is randomly sampled from $[0, 1]^2$.\n",
        "4. Set $|\\mathcal{D}_{PDE}| = 500$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "num_samples = 500\n",
        "\n",
        "class Dataset_PDE(Dataset):\n",
        "    def __init__(self, num_samples):\n",
        "        self.data = torch.rand(num_samples, 2, requires_grad=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "dataset_train_PDE = Dataset_PDE(num_samples)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5 (5 points, coding task)\n",
        "\n",
        "In this part, you are asked to define a `DataLoader` object called `dataloader_PDE`:\n",
        "\n",
        "1. `dataset = dataset_train_PDE`\n",
        "2. `batch_size = 32`\n",
        "3. `shuffle = True`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "batch_size_PDE = 32\n",
        "\n",
        "dataloader_PDE = DataLoader(dataset_train_PDE, batch_size=batch_size_PDE, shuffle=True)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 6 (10 points, coding task)\n",
        "\n",
        "In this part, you are asked to create the dataset $\\mathcal{D}_{IC}$.\n",
        "\n",
        "1. Define dataset $\\mathcal{D}_{IC}$ in the way that for each $(t, x) \\in \\mathcal{D}_{IC}$, $t$ is fixed at 0 and $x$ is evenly sampled from $\\{0, 0.01, 0.02, \\cdots, 0.98, 0.99, 1\\}$. Therefore, $|\\mathcal{D}_{IC}| = 101$.\n",
        "2. The dataset shall be a tensor with name `dataset_train_IC` and shape `(101, 2)`.\n",
        "3. Set `dataset_train_IC.requires_grad = True`.\n",
        "4. Print `dataset_train_IC.requires_grad` and `dataset_train_IC.shape`.\n",
        "5. Define tensor `u_IC` to be the ground-truth functional values of all data in $\\mathcal{D}_{IC}$ (You can find the formula from Part 1).\n",
        "6. Set `u_IC.requires_grad = True` and `u_IC.shape = (101, 1)`.\n",
        "7. Print `u_IC.requires_grad` and `u_IC.shape`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "num_samples = 101\n",
        "\n",
        "dataset_train_IC = torch.stack([torch.zeros(num_samples), torch.linspace(0, 1, num_samples)], dim=1)\n",
        "\n",
        "print(dataset_train_IC.requires_grad)\n",
        "print(dataset_train_IC.shape)\n",
        "\n",
        "u_IC = torch.sin(torch.pi * dataset_train_IC[:,1].view(-1,1))\n",
        "u_IC.requires_grad_(True)\n",
        "\n",
        "print(u_IC.requires_grad)\n",
        "print(u_IC.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 7 (10 points, coding task)\n",
        "\n",
        "In this part, you are asked to create the dataset $\\mathcal{D}_{BC}$.\n",
        "\n",
        "1. Define dataset $\\mathcal{D}_{BC}$ in the way that for each $(t, x) \\in \\mathcal{D}_{BC}$, $x$ is either 0 or 1, and $t$ is evenly sampled from $\\{0, 0.01, 0.02, \\cdots, 0.98, 0.99, 1\\}$. Therefore, $|\\mathcal{D}_{BC}| = 2 \\cdot 101 = 202$.\n",
        "2. The dataset shall be a tensor with name `dataset_train_BC` and shape `(202, 2)`.\n",
        "3. Set `dataset_train_BC.requires_grad = True`.\n",
        "4. Print `dataset_train_BC.requires_grad` and `dataset_train_BC.shape`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "num_samples = 202\n",
        "\n",
        "data_0 = torch.stack([torch.linspace(0, 1, num_samples//2), torch.zeros(num_samples//2)], dim=1)\n",
        "data_1 = torch.stack([torch.linspace(0, 1, num_samples//2), torch.ones(num_samples//2)], dim=1)\n",
        "dataset_train_BC = torch.cat([data_0, data_1], dim=0)\n",
        "dataset_train_BC.requires_grad_(True)\n",
        "\n",
        "print(dataset_train_BC.requires_grad)\n",
        "print(dataset_train_BC.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 8 (5 points, coding task)\n",
        "\n",
        "In this part, you are asked to configure your optimizer.\n",
        "\n",
        "1. Define an optimizer object called `optimizer`.\n",
        "2. Configure the optimization method as `Adam`.\n",
        "3. Set the learning rate as `1e-3`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "lr = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 9 (10 points, coding task)\n",
        "\n",
        "The purpose of this part is to guide you to learn using `torch.autograd.grad`.\n",
        "\n",
        "For each given input $(t, x)$, we not only compute $U(t, x \\mid \\theta)$ (output from the model), but also its 1st and 2nd order partial derivatives.\n",
        "\n",
        "In PyTorch, these can be done by using `torch.autograd.grad`.\n",
        "\n",
        "### Part 9.1\n",
        "\n",
        "Consider the following function\n",
        "\n",
        "$$f(p, q) = p^2 + q^3 + pq^2$$\n",
        "\n",
        "Do the following tasks at $(p, q) = (1, 2)$:\n",
        "\n",
        "1. Define tensors `p` and `q` that have values `1.0` and `2.0` (float data type), respectively, an identical shape `()` (that is, 0-dim), and `requires_grad = True`.\n",
        "\n",
        "2. Compute tensor `f` according to the formula above.\n",
        "\n",
        "3. Compute $\\frac{\\partial f(p,q)}{\\partial p}$ by using `f_p = autograd.grad(f, p, create_graph=True)[0]`. Print `f_p`.\n",
        "\n",
        "4. Compute $\\frac{\\partial f(p,q)}{\\partial q}$ by using `f_q = autograd.grad(f, q, create_graph=True)[0]`. Print `f_q`.\n",
        "\n",
        "5. Compute $\\frac{\\partial^2 f(p,q)}{\\partial p^2}$ by using `f_pp = autograd.grad(f_p, p, create_graph=True)[0]`. Print `f_pp`.\n",
        "\n",
        "6. Compute $\\frac{\\partial^2 f(p,q)}{\\partial q^2}$ by using `f_qq = autograd.grad(f_q, q, create_graph=True)[0]`. Print `f_qq`.\n",
        "\n",
        "7. Compute $\\frac{\\partial^2 f(p,q)}{\\partial p \\partial q}$ by using `f_pq = autograd.grad(f_p, q, create_graph=True)[0]`. Print `f_pq`.\n",
        "\n",
        "8. Compute $\\frac{\\partial^3 f(p,q)}{\\partial q^3}$ by using `f_qqq = autograd.grad(f_qq, q, create_graph=True)[0]`. Print `f_qqq`.\n",
        "\n",
        "### Part 9.2\n",
        "\n",
        "Consider the following function\n",
        "\n",
        "$$g(x) = x^2$$\n",
        "\n",
        "Let $x$ be a vector with values $0, 0.1, \\cdots, 0.9, 1$.\n",
        "\n",
        "Do the following tasks.\n",
        "\n",
        "1. Generate `x` as a 1-dim tensor and set `x.requires_grad = True`.\n",
        "\n",
        "2. Generate `g = x**2`. Thus, `g` has the same shape as `x`.\n",
        "\n",
        "3. Define `g_x` to be an element-wise 1st-order derivative of function $g$ with respect to $x$. Thus, `g_x` has the same shape as `x`. Write code to compute `g_x`. Print `g_x` and `g_x.shape`.\n",
        "   - **Hint:** by using `autograd.grad(f, x, create_graph=True)[0]`, tensor `x` can be with any dimension, but tensor `f` must be with dimension 0. In this problem, tensor `g` is not with dimension 0. So you need to think about how to address this issue.\n",
        "\n",
        "4. Define `g_xx` to be an element-wise 2nd-order derivative of function $g$ with respect to $x$. Thus, `g_xx` has the same shape as `x`. Write code to compute `g_xx`. Print `g_xx` and `g_xx.shape`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "# Part 9.1\n",
        "p = torch.tensor(1.0, requires_grad=True)\n",
        "q = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "f = p**2 + q**3 + p*q**2\n",
        "\n",
        "f_p = autograd.grad(f, p, create_graph=True)[0]\n",
        "print(f_p)\n",
        "\n",
        "f_q = autograd.grad(f, q, create_graph=True)[0]\n",
        "print(f_q)\n",
        "\n",
        "f_pp = autograd.grad(f_p, p, create_graph=True)[0]\n",
        "print(f_pp)\n",
        "\n",
        "f_qq = autograd.grad(f_q, q, create_graph=True)[0]\n",
        "print(f_qq)\n",
        "\n",
        "f_pq = autograd.grad(f_p, q, create_graph=True)[0]\n",
        "print(f_pq)\n",
        "\n",
        "f_qqq = autograd.grad(f_qq, q, create_graph=True)[0]\n",
        "print(f_qqq)\n",
        "\n",
        "# Part 9.2\n",
        "\n",
        "x = torch.linspace(0, 1, 10)\n",
        "x.requires_grad_(True)\n",
        "\n",
        "g = x**2\n",
        "g_x = autograd.grad(torch.sum(g), x, create_graph=True)[0]\n",
        "print(g_x)\n",
        "print(g_x.shape)\n",
        "\n",
        "g_xx = autograd.grad(torch.sum(g_x), x, create_graph=True)[0]\n",
        "print(g_xx)\n",
        "print(g_xx.shape)\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 10 (10 points, coding task)\n",
        "\n",
        "This part asks you to do a mini-batch training of the model.\n",
        "\n",
        "1. Set the parameter in the PDE `alpha = 0.1`. (This is not for learning. In PINN, we know the exact form of a PDE. We just need neural networks to help us solve it.)\n",
        "\n",
        "2. Set the number of epochs as `1000`.\n",
        "\n",
        "3. Define `device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")`\n",
        "\n",
        "4. While iterating over epochs, use `tqdm` to track the progress: `for epoch in tqdm(range(num_epochs)):`\n",
        "\n",
        "5. In each epoch,\n",
        "   1. Configure the model to the training mode.\n",
        "   2. Iterate over all mini-batches of `dataset_train_PDE`.\n",
        "   3. For each of the above mini-batch of the PDE dataset, while computing the total loss function, you also need to use all data in `dataset_train_IC` and `dataset_train_BC`.\n",
        "   4. Do all these tasks on GPU.\n",
        "\n",
        "6. In each epoch, after training over all mini-batches, if the epoch index is divisible by 100, do the following tasks:\n",
        "   1. Configure the model to the evaluation mode.\n",
        "   2. Compute the total loss over the entire three datasets: `dataset_train_PDE`, `dataset_train_IC`, `dataset_train_BC`.\n",
        "   3. Print the epoch index, the residual loss from PDE, the IC loss, the BC loss, and the total loss.\n",
        "   4. Do all these tasks on CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "alpha = 0.1\n",
        "num_epochs = 1000\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    for batch_PDE in dataloader_PDE:\n",
        "        batch_PDE = batch_PDE.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        U_PDE = model(batch_PDE)\n",
        "        U_t_and_x_PDE = autograd.grad(torch.sum(U_PDE), batch_PDE, create_graph=True)[0]\n",
        "        U_t_PDE = U_t_and_x_PDE[:,0]\n",
        "        U_x_PDE = U_t_and_x_PDE[:,1]\n",
        "        U_xx_PDE = autograd.grad(torch.sum(U_x_PDE), batch_PDE, create_graph=True)[0][:,1]\n",
        "        loss_PDE = torch.mean((U_t_PDE - alpha * U_xx_PDE)**2)\n",
        "\n",
        "        U_IC = model(dataset_train_IC.to(device))\n",
        "        loss_IC = torch.mean((U_IC - u_IC.to(device))**2)\n",
        "\n",
        "        U_BC = model(dataset_train_BC.to(device))\n",
        "        loss_BC = torch.mean(U_BC**2)\n",
        "\n",
        "        loss = loss_PDE + loss_IC + loss_BC\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        model.eval()\n",
        "        model.to('cpu')\n",
        "        batch_PDE = next(iter(dataloader_PDE))\n",
        "        batch_PDE.requires_grad_(True)\n",
        "        U_PDE = model(batch_PDE)\n",
        "        U_t_and_x_PDE = autograd.grad(torch.sum(U_PDE), batch_PDE, create_graph=True)[0]\n",
        "        U_xx_PDE = autograd.grad(torch.sum(U_t_and_x_PDE[:,1]), batch_PDE, create_graph=True)[0][:,1]\n",
        "        loss_PDE = torch.mean((U_t_and_x_PDE[:,0] - alpha * U_xx_PDE)**2)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            U_IC = model(dataset_train_IC)\n",
        "            loss_IC = torch.mean((U_IC - u_IC)**2)\n",
        "            U_BC = model(dataset_train_BC)\n",
        "            loss_BC = torch.mean(model(dataset_train_BC)**2)\n",
        "            loss = loss_PDE + loss_IC + loss_BC\n",
        "\n",
        "        print(f\"{loss_PDE.item():.4e}, {loss_IC.item():.4e}, {loss_BC.item():.4e}\")\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4e}\")\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 11 (5 points, non-coding task)\n",
        "\n",
        "Answer the following free-response question.\n",
        "\n",
        "In each epoch, while iterating over each mini-batch of `dataset_PDE`, why do we consider the entire data points in `dataset_IC` and `dataset_BC`, rather than also a mini-batch in these two datasets?\n",
        "\n",
        "To be specific, recall that the mini-batch size of `dataset_PDE` is 32. The sizes of `dataset_IC` and `dataset_BC` are 101 and 202, respectively.\n",
        "\n",
        "Then in each iteration, the number of data points that we use to compute the total loss value is $32 + 101 + 202 = 335$.\n",
        "\n",
        "Suppose we also do mini-batch on the IC and BC datasets with the same mini-batch size, say, 32. Then in each iteration, the number of data points that we use is $32 + 32 + 32 = 96$.\n",
        "\n",
        "We adopt the former approach, not the latter approach. You need to explain why.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "In training, we always need to ensure that all IC and BC constraints are satisfied. Therefore, we enforce these constraints all the time.\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 12 (10 points, coding task)\n",
        "\n",
        "In this part, you are asked to do the following tasks to test the effectiveness of our PINN model.\n",
        "\n",
        "1. Generate a dataset $\\{(t, x) \\in \\{0, 0.01, \\cdots, 1\\}^2\\}$. Save the dataset as a tensor with name `tx_test` and shape `(101, 2)`.\n",
        "\n",
        "2. For each data point, compute $u(t, x)$ whose formula is given in Part 1. Save the result as a tensor with name `u_test` and shape `(101, 2)`.\n",
        "\n",
        "3. For each data point, use our trained PINN model to compute the predicted value $U(t, x \\mid \\theta)$. Save the result as a tensor with name `U_test` and shape `(101, 2)`.\n",
        "\n",
        "4. Print the mean squared error between `u_test` and `U_test`.\n",
        "\n",
        "5. Generate two 2-dim scatter plots for $(t, x)$ by using the above data points.\n",
        "   - In Figure 1, the value on each position is the ground-truth temperature $u(t, x)$.\n",
        "   - In Figure 2, the value on each position is the predicted temperature $U(t, x \\mid \\theta)$.\n",
        "   - In each plot,\n",
        "     - Set `c` as the values on those scattered positions\n",
        "     - Set `cmap='viridis'`\n",
        "     - Add `plt.colorbar(label='Value')`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### WRITE YOUR SOLUTION HERE ###\n",
        "\n",
        "model.to('cpu')\n",
        "data_1dim = torch.linspace(0, 1, 101)\n",
        "data_grid = torch.meshgrid(data_1dim, data_1dim)\n",
        "tx_test = torch.stack([data_grid[0].reshape(-1), data_grid[1].reshape(-1)], dim=1)\n",
        "u_test = torch.exp(- alpha * torch.pi**2 * tx_test[:,0]) * torch.sin(torch.pi * tx_test[:,1])\n",
        "U_test = model(tx_test).reshape(-1).detach()\n",
        "\n",
        "mse = torch.mean((u_test - U_test)**2).item()\n",
        "print(mse)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.scatter(tx_test[:,0], tx_test[:,1], c=u_test, cmap='viridis')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('x')\n",
        "plt.colorbar(label='Value')\n",
        "plt.title('Ground-truth')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(2)\n",
        "plt.scatter(tx_test[:,0], tx_test[:,1], c=U_test, cmap='viridis')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('x')\n",
        "plt.colorbar(label='Value')\n",
        "plt.title('Predicted')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\"\"\" END OF THIS PART \"\"\""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
